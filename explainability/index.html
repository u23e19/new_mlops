<!doctype html>
<html data-n-head-ssr lang="en" data-n-head="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>MLOps Toys | A Curated List of Machine Learning Projects</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width,initial-scale=1"><meta data-n-head="ssr" name="theme-color" content="#ffffff"><meta data-n-head="ssr" name="msapplication-config" content="/favicons/browserconfig.xml"><meta data-n-head="ssr" name="msapplication-TileColor" content="#48cfad"><meta data-n-head="ssr" http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate"><meta data-n-head="ssr" http-equiv="Pragma" content="no-cache"><meta data-n-head="ssr" http-equiv="Expires" content="0"><meta data-n-head="ssr" name="title" content="MLOps Toys | A Curated List of Machine Learning Projects"><meta data-n-head="ssr" name="og:title" content="MLOps Toys | A Curated List of Machine Learning Projects"><meta data-n-head="ssr" name="twitter:title" content="MLOps Toys | A Curated List of Machine Learning Projects"><meta data-n-head="ssr" data-hid="description" name="description" content="Check out this curated list of the most useful MLOps tools, projects and more. Have something to add? Let us know!"><meta data-n-head="ssr" data-hid="og:description" name="og:description" content="Check out this curated list of the most useful MLOps tools, projects and more. Have something to add? Let us know!"><meta data-n-head="ssr" data-hid="twitter:description" name="twitter:description" content="Check out this curated list of the most useful MLOps tools, projects and more. Have something to add? Let us know!"><meta data-n-head="ssr" name="og:type" content="website"><meta data-n-head="ssr" name="og:url" content="https://mlops.toys"><meta data-n-head="ssr" name="twitter:url" content="https://mlops.toys"><meta data-n-head="ssr" name="keywords" content="mlops, mlops tools, machine learning, production machine learning, awesome mlops, awesome machine learning"><meta data-n-head="ssr" name="og:image" content="https://mlops.toys/images/seo/image.png"><meta data-n-head="ssr" name="twitter:image" content="https://mlops.toys/images/seo/twitter-image.png"><meta data-n-head="ssr" name="twitter:card" content="summary_large_image"><meta data-n-head="ssr" data-hid="charset" charset="utf-8"><meta data-n-head="ssr" data-hid="mobile-web-app-capable" name="mobile-web-app-capable" content="yes"><meta data-n-head="ssr" data-hid="apple-mobile-web-app-title" name="apple-mobile-web-app-title" content="mlops.toys"><meta data-n-head="ssr" data-hid="og:site_name" name="og:site_name" property="og:site_name" content="mlops.toys"><link data-n-head="ssr" rel="apple-touch-icon" sizes="180x180" href="/favicons/apple-touch-icon.png"><link data-n-head="ssr" rel="icon" type="image/png" sizes="32x32" href="/favicons/favicon-32x32.png"><link data-n-head="ssr" rel="icon" type="image/png" sizes="16x16" href="/favicons/favicon-16x16.png"><link data-n-head="ssr" rel="manifest" href="/favicons/site.webmanifest"><link data-n-head="ssr" rel="mask-icon" href="/favicons/safari-pinned-tab.svg" color="#48cfad"><link data-n-head="ssr" rel="shortcut icon" href="/favicons/favicon.ico"><link data-n-head="ssr" data-hid="shortcut-icon" rel="shortcut icon" href="/_nuxt/icons/icon_64x64.c1c3d9.png"><link data-n-head="ssr" data-hid="apple-touch-icon" rel="apple-touch-icon" href="/_nuxt/icons/icon_512x512.c1c3d9.png" sizes="512x512"><link data-n-head="ssr" rel="manifest" href="/_nuxt/manifest.fc7bcd48.json" data-hid="manifest"><script data-n-head="ssr" data-hid="gtm-script">window._gtm_init||(window._gtm_init=1,function(t,e,n,a,o){t[n]=1==t[n]||"yes"==e[n]||1==e[n]||1==e.msDoNotTrack||t[a]&&t[a][o]&&t[a][o]()?1:0}(window,navigator,"doNotTrack","external","msTrackingProtectionEnabled"),function(a,o,i,g,m){a[m]={},a._gtm_inject=function(t){var e,n;a.doNotTrack||a[m][t]||(a[m][t]=1,a[g]=a[g]||[],a[g].push({"gtm.start":(new Date).getTime(),event:"gtm.js"}),e=o.getElementsByTagName(i)[0],(n=o.createElement(i)).async=!0,n.src="https://www.googletagmanager.com/gtm.js?id="+t,e.parentNode.insertBefore(n,e))},a._gtm_inject("GTM-53TSBBF")}(window,document,"script","dataLayer","_gtm_ids"))</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"lakeFS Video","description":"lakeFS is an open-source data lake management platform that transforms your object storage into a Git-like repository. lakeFS enables you to manage your data lake the way you manage your code. Run parallel pipelines for experimentation and CI/CD for your data.","thumbnailUrl":"https://i.ytimg.com/vi/xThorxDzmrw/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/xThorxDzmrw"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"WhyLabs Video","description":"The WhyLabs Observability Platform enables any AI practitioner to set up AI monitoring in three easy steps. It follows the standard DevOps model of installing a lightweight logging agent (whylogs) alongside your model and sending data profiles to a fully self-service SaaS platform (WhyLabs). On the platform, you can analyze your profiles to see how your model is performing and get automatically get alerted on changes. The platform includes:","thumbnailUrl":"https://i.ytimg.com/vi/UsDsLEpigBw/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/UsDsLEpigBw"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Weights &amp; Biases Video","description":"Track and visualize all the pieces of your machine learning pipeline, from datasets to production models.","thumbnailUrl":"https://i.ytimg.com/vi/91HhNtmb0B4/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/91HhNtmb0B4"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Valohai Video","description":"Valohai is an MLOps platform that handles machine orchestration, automatic reproducibility and deployment.","thumbnailUrl":"https://i.ytimg.com/vi/jnrSd2nqCWg/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/jnrSd2nqCWg"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Triton Inference Server Video","description":"Triton Inference Server simplifies the deployment of AI models at scale in production.","thumbnailUrl":"https://i.ytimg.com/vi/1DUqD3zMwB4/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/1DUqD3zMwB4"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"TorchServe Video","description":"TorchServe is a flexible and easy to use tool for serving PyTorch models.","thumbnailUrl":"https://i.ytimg.com/vi/9lMMCwVhPpo/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/9lMMCwVhPpo"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Tensorflow Serving Video","description":"TensorFlow Serving is a flexible, high-performance serving system for TF models, designed for production environments.","thumbnailUrl":"https://i.ytimg.com/vi/q_IkJcPyNl0/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/q_IkJcPyNl0"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Syndicai Video","description":"Syndicai is a cloud platform that deploys, manages, and scales any trained AI model in minutes with no configuration &amp; infrastructure setup.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Stoke Video","description":"stoke is a lightweight wrapper for PyTorch that provides a simple declarative API for context switching between devices (e.g. CPU, GPU), distributed modes, mixed-precision, and PyTorch extensions. This allows you to switch from local full-precision CPU to mixed-precision distributed multi-GPU with extensions (like optimizer state sharding) by simply changing a few declarative flags. Additionally, stoke exposes configuration settings for every underlying backend for those that want configurability and raw access to the underlying libraries. In short, stoke is the best of PyTorch Lightning Accelerators disconnected from the rest of PyTorch Lightning. Write whatever PyTorch code you want, but leave device and backend context switching to stoke.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Spock Video","description":"spock is a framework that helps manage complex parameter configurations during research and development of Python applications. spock lets you focus on the code you need to write instead of re-implementing boilerplate code like creating ArgParsers, reading configuration files, implementing traceability etc. In short, spock configurations are defined by simple and familiar class-based structures. This allows spock to support inheritance, read from multiple markdown formats, and allow hierarchical configuration by composition.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Spell Video","description":"Spell is an **end-to-end deep learning platform** that automates complex ML infrastructure and operational work required to train and deploy AI models. Spell is fully hybrid-cloud, and can deploy easily into any cloud or on-prem hardware.","thumbnailUrl":"https://i.ytimg.com/vi/s2E5sfmEbec/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/s2E5sfmEbec"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Seldon Core Video","description":"Seldon Core makes it easier and faster to deploy your machine learning models and experiments at scale on Kubernetes.","thumbnailUrl":"https://i.ytimg.com/vi/Xildxp_CsmA/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/Xildxp_CsmA"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Sagify Video","description":"A command-line utility to train and deploy Machine Learning and Deep Learning models on AWS SageMaker in a few simple steps.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"SHAP Video","description":"SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"PrimeHub Video","description":"PrimeHub, an open-source pluggable MLOps platform on the top of Kubernetes for teams of data scientists and administrators. PrimeHub equips enterprises with consistent yet flexible tools to develop, train, and deploy ML models at scale. By improving the iterative process of data science, data teams can collaborate closely and innovate fast.","thumbnailUrl":"https://i.ytimg.com/vi/3ZOPXR9L2Ho/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/3ZOPXR9L2Ho"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Ploomber Video","description":"Develop and test workflows locally, seamlessly execute them in a distributed environment.","thumbnailUrl":"https://i.ytimg.com/vi/XCgX1AszVF4/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/XCgX1AszVF4"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Pachyderm Video","description":"Pachyderm is a tool for version-controlled, automated, end-to-end data pipelines for data science.","thumbnailUrl":"https://i.ytimg.com/vi/r9CrtAtuJDI/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/r9CrtAtuJDI"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Orchest Video","description":"Build data pipelines, the easy way!","thumbnailUrl":"https://i.ytimg.com/vi/BUpSVE2mtz4/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/BUpSVE2mtz4"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"OpenVINO™ Model Server Video","description":"OpenVINO™ Model Server (OVMS) is a scalable, high-performance solution for serving machine learning models optimized for Intel® architectures.","thumbnailUrl":"https://i.ytimg.com/vi/AfytPrAVdfc/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/AfytPrAVdfc"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"OpenPAI Video","description":"OpenPAI is an open-source platform that provides complete AI model training and resource management capabilities, it is easy to extend and supports on-premise, cloud, and hybrid environments on various scales.","thumbnailUrl":"https://i.ytimg.com/vi/C9eRaqqAOeY/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/C9eRaqqAOeY"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Neptune Video","description":"Neptune is a lightweight experiment logging/tracking tool that helps you with your machine learning experiments.","thumbnailUrl":"https://i.ytimg.com/vi/w9S5srkfSI4/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/w9S5srkfSI4"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"MLRun Video","description":"MLRun is an end-to-end open-source MLOps orchestration framework to manage and automate your entire analytics and machine learning lifecycle, from data ingestion, through model development to full pipeline deployment. MLRun eases the development of machine learning pipelines at scale and helps ML teams build a robust process for moving from the research phase to fully operational production deployments.","thumbnailUrl":"https://i.ytimg.com/vi/imiTr1aXRKU/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/imiTr1aXRKU"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"MLFlow Video","description":"MLflow is a platform to streamline machine learning development, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models.","thumbnailUrl":"https://i.ytimg.com/vi/VokAGy8C6K4/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/VokAGy8C6K4"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Lime Video","description":"This project is about explaining what machine learning classifiers (or models) are doing. At the moment, we support explaining individual predictions for text classifiers or classifiers that act on tables (numpy arrays of numerical or categorical data) or. images, with a package called lime (short for local interpretable model-agnostic explanations). Lime is based on the work presented in this paper (bibtex here for citation).","thumbnailUrl":"https://i.ytimg.com/vi/hUnRCxnydCc/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/hUnRCxnydCc"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Kubeflow Video","description":"The Kubeflow project is dedicated to making deployments of machine learning (ML) workflows on Kubernetes simple, portable and scalable.","thumbnailUrl":"https://i.ytimg.com/vi/cTZArDgbIWw/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/cTZArDgbIWw"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Katonic.ai Video","description":"Katonic MLOps Platform is a collaborative platform with a Unified UI to manage all data science activities in one place and introduce MLOps practice into the production systems of customers and developers. It is a collection of cloud-native tools for all of these stages of MLOps:","thumbnailUrl":"https://i.ytimg.com/vi/cGl5CqSiPLw/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/cGl5CqSiPLw"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"KFServing Video","description":"KFServing enables serverless inferencing on Kubernetes to solve production model serving use cases.","thumbnailUrl":"https://i.ytimg.com/vi/lj_X2ND2BBI/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/lj_X2ND2BBI"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"InterpretML Video","description":"InterpretML is an open-source package that incorporates state-of-the-art machine learning interpretability techniques under one roof. With this package, you can train interpretable glassbox models and explain blackbox systems. InterpretML helps you understand your model&#x27;s global behavior, or understand the reasons behind individual predictions.","thumbnailUrl":"https://i.ytimg.com/vi/WwBeKMQ0-I8/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/WwBeKMQ0-I8"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Iguazio Data Science Platform Video","description":"The Iguazio Data Science Platform accelerates and scales development, deployment and management of your AI applications with MLOps and end-to-end automation of machine learning pipelines. The platform includes an online and offline feature store, fully integrated with automated model monitoring and drift detection, model serving and dynamic scaling capabilities, all packaged in an open and managed platform.","thumbnailUrl":"https://i.ytimg.com/vi/BzQQ1X4LgcQ/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/BzQQ1X4LgcQ"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Hypervector Video","description":"Provides API-powered **synthetic data test fixtures** for your tabular data-enabled features — enabling regression and integration tests to be easily built and deployed for your production ML models and data science components","thumbnailUrl":"https://i.ytimg.com/vi/877h1umtJAo/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/877h1umtJAo"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Hopsworks Video","description":"The Hopsworks Feature Store manages your features for training and serving models.","thumbnailUrl":"https://i.ytimg.com/vi/uVBeoeENEcI/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/uVBeoeENEcI"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Flyte Video","description":"Flyte makes it easy to create concurrent, scalable, and maintainable workflows for machine learning and data processing.","thumbnailUrl":"https://i.ytimg.com/vi/1BjXC5TZAiI/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/1BjXC5TZAiI"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Fiddler Video","description":"Continuously monitor, explain, and analyze AI systems at scale. With actionable insights build trustworthy, fair, and responsible AI monitoring.","thumbnailUrl":"https://i.ytimg.com/vi/gqnDqrIzabw/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/gqnDqrIzabw"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Feast Video","description":"Feast is an operational data system for managing and serving machine learning features to models in production.","thumbnailUrl":"https://i.ytimg.com/vi/DaNv-Wf1MBA/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/DaNv-Wf1MBA"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Evidently AI Video","description":"Evidently helps analyze machine learning models during validation or production monitoring. It generates interactive reports from pandas DataFramesor csv files.","thumbnailUrl":"https://i.ytimg.com/vi/2suSzXlY_7Y/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/2suSzXlY_7Y"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"ELI5 Video","description":"ELI5 is a Python library which allows to visualize and debug various Machine Learning models using unified API. It has built-in support for several ML frameworks and provides a way to explain black-box models.","thumbnailUrl":"https://i.ytimg.com/vi/s-yT5Is1G1A/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/s-yT5Is1G1A"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Determined Video","description":"Determined is an open-source deep learning training platform that makes building models fast and easy.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Deepchecks Video","description":"Validate and monitor your data and models during training, production and new version releases.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"DVC Video","description":"DVC is an open-source tool for data science and machine learning projects.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"DAGsHub Video","description":"DAGsHub enables data scientists and ML engineers to work together, effectively. Integrating open-source tools like Git, DVC, MLflow, and Jenkins so that you can track and version code, data, models, pipelines, and experiments in one place.","thumbnailUrl":"https://i.ytimg.com/vi/lrzdqEwzoo8/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/lrzdqEwzoo8"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Cortex Video","description":"Cortex makes it simple to deploy machine learning models in production.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Comet Video","description":"Comet enables data scientists and teams to track, compare, explain and optimize experiments and models across the model’s entire lifecycle. From training to production.","thumbnailUrl":"https://i.ytimg.com/vi/cX5tx202PXM/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/cX5tx202PXM"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"ClearML Video","description":"ClearML is an open source suite of tools that automates preparing, executing, and analyzing machine learning experiments.","thumbnailUrl":"https://i.ytimg.com/vi/Y5tPfUm9Ghg/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/Y5tPfUm9Ghg"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"CML Video","description":"Open-source library for implementing CI/CD in machine learning projects.","thumbnailUrl":"https://i.ytimg.com/vi/9BgIDqAzfuA/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/9BgIDqAzfuA"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Bytehub Video","description":"An easy-to-use feature store.","thumbnailUrl":"https://i.ytimg.com/vi/ucAlzaJoqeU/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/ucAlzaJoqeU"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Butterfree Video","description":"A tool for building feature stores. Transform your raw data into beautiful features.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Bodywork Video","description":"Bodywork deploys machine learning projects developed in Python, to Kubernetes. It helps you:","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"BentoML Video","description":"BentoML is a flexible, high-performance framework for serving, managing, and deploying machine learning models.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Aporia Video","description":"With Aporia data scientists and ML engineers can easily build monitoring for their ML models running in production.","thumbnailUrl":"https://i.ytimg.com/vi/9oyZDXrmWMA/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/9oyZDXrmWMA"}</script><script data-n-head="ssr" type="application/ld+json">{"@context":"http://schema.org","@type":"VideoObject","name":"Aim Video","description":"Compare 1000s of AI experiments at once.","thumbnailUrl":"https://i.ytimg.com/vi/undefined/default.jpg","uploadDate":"2021-07-10T10:38:33Z","embedUrl":"https://www.youtube.com/embed/undefined"}</script><link rel="preload" href="/_nuxt/ace382d.js" as="script"><link rel="preload" href="/_nuxt/67a9037.js" as="script"><link rel="preload" href="/_nuxt/199d7de.js" as="script"><link rel="preload" href="/_nuxt/44ea7cd.js" as="script"><link rel="preload" href="/_nuxt/22f13d0.js" as="script"><link rel="preload" href="/_nuxt/81af258.js" as="script"><link rel="preload" href="/_nuxt/e3e98e8.js" as="script"><style data-vue-ssr-id="890c9cc4:0 b682ae5a:0 5557d5f8:0 a0599564:0 631c3b90:0 9b0d47a6:0 73ce5f68:0 59e23242:0">/*! tailwindcss v2.1.2 | MIT License | https://tailwindcss.com*//*! modern-normalize v1.0.0 | MIT License | https://github.com/sindresorhus/modern-normalize */*,::after,::before{box-sizing:border-box}:root{-moz-tab-size:4;-o-tab-size:4;tab-size:4}html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}body{font-family:system-ui,-apple-system,'Segoe UI',Roboto,Helvetica,Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji'}hr{height:0;color:inherit}abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,pre,samp{font-family:ui-monospace,SFMono-Regular,Consolas,'Liberation Mono',Menlo,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{text-indent:0;border-color:inherit}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,select{text-transform:none}[type=button],button{-webkit-appearance:button}legend{padding:0}progress{vertical-align:baseline}summary{display:list-item}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}button{background-color:transparent;background-image:none}button:focus{outline:1px dotted;outline:5px auto -webkit-focus-ring-color}fieldset{margin:0;padding:0}ol,ul{list-style:none;margin:0;padding:0}html{font-family:Inter,sans-serif;line-height:1.5}body{font-family:inherit;line-height:inherit}*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e5e7eb}hr{border-top-width:1px}img{border-style:solid}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{opacity:1;color:#9ca3af}input::placeholder,textarea::placeholder{opacity:1;color:#9ca3af}button{cursor:pointer}table{border-collapse:collapse}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit}code,kbd,pre,samp{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}@font-face{font-family:Inter;src:url(/_nuxt/fonts/Inter-VariableFont_slnt,wght.f958c68.ttf) format("truetype supports variations"),url(/_nuxt/fonts/Inter-VariableFont_slnt,wght.f958c68.ttf) format("truetype-variations");font-weight:100 900}button,input,textarea{outline:0!important}html{scroll-behavior:smooth}.container{width:100%}.aspect-w-16{position:relative;padding-bottom:calc(var(--tw-aspect-h)/ var(--tw-aspect-w) * 100%)}.aspect-w-16>*{position:absolute;height:100%;width:100%;top:0;right:0;bottom:0;left:0}.aspect-w-16{--tw-aspect-w:16}.aspect-h-9{--tw-aspect-h:9}.appearance-none{-webkit-appearance:none;-moz-appearance:none;appearance:none}.bg-gray-50{--tw-bg-opacity:1;background-color:rgba(249,250,251,var(--tw-bg-opacity))}.bg-gray-900{--tw-bg-opacity:1;background-color:rgba(17,24,39,var(--tw-bg-opacity))}.bg-purple-600{--tw-bg-opacity:1;background-color:rgba(79,70,229,var(--tw-bg-opacity))}.hover\:bg-gray-50:hover{--tw-bg-opacity:1;background-color:rgba(249,250,251,var(--tw-bg-opacity))}.hover\:bg-gray-100:hover{--tw-bg-opacity:1;background-color:rgba(243,244,246,var(--tw-bg-opacity))}.hover\:bg-gray-800:hover{--tw-bg-opacity:1;background-color:rgba(31,41,55,var(--tw-bg-opacity))}.hover\:bg-purple-700:hover{--tw-bg-opacity:1;background-color:rgba(67,56,202,var(--tw-bg-opacity))}.bg-gradient-to-r{background-image:linear-gradient(to right,var(--tw-gradient-stops))}.bg-gradient-to-l{background-image:linear-gradient(to left,var(--tw-gradient-stops))}.from-transparent{--tw-gradient-from:transparent;--tw-gradient-stops:var(--tw-gradient-from),var(--tw-gradient-to, rgba(0, 0, 0, 0))}.to-white{--tw-gradient-to:#fff}.border-gray-200{--tw-border-opacity:1;border-color:rgba(229,231,235,var(--tw-border-opacity))}.group:hover .group-hover\:border-purple-300{--tw-border-opacity:1;border-color:rgba(165,180,252,var(--tw-border-opacity))}.focus\:border-purple-300:focus{--tw-border-opacity:1;border-color:rgba(165,180,252,var(--tw-border-opacity))}.rounded{border-radius:.25rem}.rounded-md{border-radius:.375rem}.border-solid{border-style:solid}.border{border-width:1px}.border-b{border-bottom-width:1px}.block{display:block}.inline-block{display:inline-block}.inline{display:inline}.flex{display:flex}.inline-flex{display:inline-flex}.table{display:table}.hidden{display:none}.flex-col{flex-direction:column}.flex-wrap{flex-wrap:wrap}.flex-nowrap{flex-wrap:nowrap}.items-center{align-items:center}.justify-start{justify-content:flex-start}.justify-center{justify-content:center}.justify-between{justify-content:space-between}.justify-around{justify-content:space-around}.flex-1{flex:1 1 0%}.flex-shrink-0{flex-shrink:0}.font-medium{font-weight:500}.font-semibold{font-weight:600}.font-bold{font-weight:700}.h-2{height:.5rem}.h-3{height:.75rem}.h-4{height:1rem}.h-5{height:1.25rem}.h-6{height:1.5rem}.h-8{height:2rem}.h-10{height:2.5rem}.h-11{height:2.75rem}.h-16{height:4rem}.h-full{height:100%}.text-3xl{font-size:36px;line-height:1.6;letter-spacing:-.025em}.text-2xl{font-size:24px;line-height:1.6;letter-spacing:-.025em}.text-xl{font-size:20px;line-height:1.6;letter-spacing:-.025em}.text-lg{font-size:18px;line-height:1.8}.text-sm{font-size:14px;line-height:1.8}.text-xs{font-size:12px;line-height:1.6}.text-zero{font-size:0}.m-1{margin:.25rem}.-m-1{margin:-.25rem}.my-1{margin-top:.25rem;margin-bottom:.25rem}.mx-2{margin-left:.5rem;margin-right:.5rem}.my-5{margin-top:1.25rem;margin-bottom:1.25rem}.mx-auto{margin-left:auto;margin-right:auto}.mt-0{margin-top:0}.mt-1{margin-top:.25rem}.mr-2{margin-right:.5rem}.mb-2{margin-bottom:.5rem}.ml-2{margin-left:.5rem}.mt-3{margin-top:.75rem}.mr-3{margin-right:.75rem}.mb-3{margin-bottom:.75rem}.ml-3{margin-left:.75rem}.mt-4{margin-top:1rem}.mr-4{margin-right:1rem}.mb-4{margin-bottom:1rem}.ml-4{margin-left:1rem}.mt-5{margin-top:1.25rem}.mr-5{margin-right:1.25rem}.mt-6{margin-top:1.5rem}.mt-8{margin-top:2rem}.mt-10{margin-top:2.5rem}.mr-10{margin-right:2.5rem}.mb-10{margin-bottom:2.5rem}.ml-10{margin-left:2.5rem}.ml-20{margin-left:5rem}.ml-auto{margin-left:auto}.mt-0\.5{margin-top:.125rem}.mt-1\.5{margin-top:.375rem}.-mt-1{margin-top:-.25rem}.-mb-6{margin-bottom:-1.5rem}.-mt-1\.5{margin-top:-.375rem}.max-w-lg{max-width:32rem}.max-w-screen{max-width:160rem}.object-cover{-o-object-fit:cover;object-fit:cover}.opacity-0{opacity:0}.hover\:opacity-70:hover{opacity:.7}.overflow-hidden{overflow:hidden}.overflow-x-auto{overflow-x:auto}.p-1{padding:.25rem}.p-10{padding:2.5rem}.py-1{padding-top:.25rem;padding-bottom:.25rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-2{padding-left:.5rem;padding-right:.5rem}.py-3{padding-top:.75rem;padding-bottom:.75rem}.px-3{padding-left:.75rem;padding-right:.75rem}.px-4{padding-left:1rem;padding-right:1rem}.py-5{padding-top:1.25rem;padding-bottom:1.25rem}.px-6{padding-left:1.5rem;padding-right:1.5rem}.py-10{padding-top:2.5rem;padding-bottom:2.5rem}.px-10{padding-left:2.5rem;padding-right:2.5rem}.px-2\.5{padding-left:.625rem;padding-right:.625rem}.pt-1{padding-top:.25rem}.pt-2{padding-top:.5rem}.pr-2{padding-right:.5rem}.pb-6{padding-bottom:1.5rem}.pr-7{padding-right:1.75rem}.pt-9{padding-top:2.25rem}.pb-10{padding-bottom:2.5rem}.pr-12{padding-right:3rem}.pl-12{padding-left:3rem}.pt-24{padding-top:6rem}.placeholder-gray-400::-moz-placeholder{--tw-placeholder-opacity:1;color:rgba(156,163,175,var(--tw-placeholder-opacity))}.placeholder-gray-400::placeholder{--tw-placeholder-opacity:1;color:rgba(156,163,175,var(--tw-placeholder-opacity))}.focus\:placeholder-gray-500:focus::-moz-placeholder{--tw-placeholder-opacity:1;color:rgba(107,114,128,var(--tw-placeholder-opacity))}.focus\:placeholder-gray-500:focus::placeholder{--tw-placeholder-opacity:1;color:rgba(107,114,128,var(--tw-placeholder-opacity))}.pointer-events-none{pointer-events:none}.static{position:static}.absolute{position:absolute}.relative{position:relative}.sticky{position:sticky}.top-0{top:0}.right-0{right:0}.bottom-0{bottom:0}.left-0{left:0}.right-10{right:2.5rem}.left-10{left:2.5rem}.bottom-14{bottom:3.5rem}.top-24{top:6rem}.-right-24{right:-6rem}.-left-24{left:-6rem}.resize{resize:both}*{--tw-shadow:0 0 #0000}.shadow-sm{--tw-shadow:0 1px 2px 0 rgba(0, 0, 0, 0.05);box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}*{--tw-ring-inset:var(--tw-empty, );/*!*//*!*/--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59, 130, 246, 0.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000}.focus\:ring:focus{--tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);--tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(3px + var(--tw-ring-offset-width)) var(--tw-ring-color);box-shadow:var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 #0000)}.focus\:ring-purple-50:focus{--tw-ring-opacity:1;--tw-ring-color:rgba(238, 242, 255, var(--tw-ring-opacity))}.text-center{text-align:center}.text-right{text-align:right}.text-white{--tw-text-opacity:1;color:rgba(255,255,255,var(--tw-text-opacity))}.text-gray-400{--tw-text-opacity:1;color:rgba(156,163,175,var(--tw-text-opacity))}.text-gray-500{--tw-text-opacity:1;color:rgba(107,114,128,var(--tw-text-opacity))}.text-gray-600{--tw-text-opacity:1;color:rgba(75,85,99,var(--tw-text-opacity))}.text-gray-900{--tw-text-opacity:1;color:rgba(17,24,39,var(--tw-text-opacity))}.text-aporia{--tw-text-opacity:1;color:rgba(72,207,173,var(--tw-text-opacity))}.text-aporiaRed{--tw-text-opacity:1;color:rgba(242,59,39,var(--tw-text-opacity))}.group:hover .group-hover\:text-purple-600{--tw-text-opacity:1;color:rgba(79,70,229,var(--tw-text-opacity))}.hover\:text-purple-600:hover{--tw-text-opacity:1;color:rgba(79,70,229,var(--tw-text-opacity))}.hover\:text-aporia:hover{--tw-text-opacity:1;color:rgba(72,207,173,var(--tw-text-opacity))}.align-top{vertical-align:top}.align-middle{vertical-align:middle}.whitespace-nowrap{white-space:nowrap}.w-2{width:.5rem}.w-3{width:.75rem}.w-4{width:1rem}.w-5{width:1.25rem}.w-6{width:1.5rem}.w-8{width:2rem}.w-10{width:2.5rem}.w-16{width:4rem}.w-7\/12{width:58.333333%}.w-full{width:100%}.z-10{z-index:10}.transform{--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;transform:translateX(var(--tw-translate-x)) translateY(var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.transform-gpu{--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;transform:translate3d(var(--tw-translate-x),var(--tw-translate-y),0) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y))}.rotate-180{--tw-rotate:180deg}.translate-x-4{--tw-translate-x:1rem}.translate-y-5{--tw-translate-y:1.25rem}.transition-all{transition-property:all;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:150ms}.transition{transition-property:background-color,border-color,color,fill,stroke,opacity,box-shadow,transform,filter,-webkit-backdrop-filter;transition-property:background-color,border-color,color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-property:background-color,border-color,color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter,-webkit-backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:150ms}.transition-colors{transition-property:background-color,border-color,color,fill,stroke;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:150ms}.transition-opacity{transition-property:opacity;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:150ms}.duration-200{transition-duration:.2s}@-webkit-keyframes spin{to{transform:rotate(360deg)}}@keyframes spin{to{transform:rotate(360deg)}}@-webkit-keyframes ping{100%,75%{transform:scale(2);opacity:0}}@keyframes ping{100%,75%{transform:scale(2);opacity:0}}@-webkit-keyframes pulse{50%{opacity:.5}}@keyframes pulse{50%{opacity:.5}}@-webkit-keyframes bounce{0%,100%{transform:translateY(-25%);-webkit-animation-timing-function:cubic-bezier(.8,0,1,1);animation-timing-function:cubic-bezier(.8,0,1,1)}50%{transform:none;-webkit-animation-timing-function:cubic-bezier(0,0,.2,1);animation-timing-function:cubic-bezier(0,0,.2,1)}}@keyframes bounce{0%,100%{transform:translateY(-25%);-webkit-animation-timing-function:cubic-bezier(.8,0,1,1);animation-timing-function:cubic-bezier(.8,0,1,1)}50%{transform:none;-webkit-animation-timing-function:cubic-bezier(0,0,.2,1);animation-timing-function:cubic-bezier(0,0,.2,1)}}.filter{--tw-blur:var(--tw-empty, );/*!*//*!*/--tw-brightness:var(--tw-empty, );/*!*//*!*/--tw-contrast:var(--tw-empty, );/*!*//*!*/--tw-grayscale:var(--tw-empty, );/*!*//*!*/--tw-hue-rotate:var(--tw-empty, );/*!*//*!*/--tw-invert:var(--tw-empty, );/*!*//*!*/--tw-saturate:var(--tw-empty, );/*!*//*!*/--tw-sepia:var(--tw-empty, );/*!*//*!*/--tw-drop-shadow:var(--tw-empty, );/*!*//*!*/filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow)}.backdrop-filter{--tw-backdrop-blur:var(--tw-empty, );/*!*//*!*/--tw-backdrop-brightness:var(--tw-empty, );/*!*//*!*/--tw-backdrop-contrast:var(--tw-empty, );/*!*//*!*/--tw-backdrop-grayscale:var(--tw-empty, );/*!*//*!*/--tw-backdrop-hue-rotate:var(--tw-empty, );/*!*//*!*/--tw-backdrop-invert:var(--tw-empty, );/*!*//*!*/--tw-backdrop-opacity:var(--tw-empty, );/*!*//*!*/--tw-backdrop-saturate:var(--tw-empty, );/*!*//*!*/--tw-backdrop-sepia:var(--tw-empty, );/*!*//*!*/-webkit-backdrop-filter:var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);backdrop-filter:var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia)}.backdrop-blur-xl{--tw-backdrop-blur:blur(24px)}.column-count-3{-moz-column-count:3;column-count:3}.column-gap-10{-moz-column-gap:2.5rem;column-gap:2.5rem}@media (max-width:1920px){.\32xl\:column-count-2{-moz-column-count:2;column-count:2}}@media (max-width:1023px){.lg\:block{display:block}.lg\:hidden{display:none}.lg\:flex-col{flex-direction:column}.lg\:font-medium{font-weight:500}.lg\:h-4{height:1rem}.lg\:h-6{height:1.5rem}.lg\:h-10{height:2.5rem}.lg\:text-xl{font-size:20px;line-height:1.6;letter-spacing:-.025em}.lg\:text-base{font-size:16px;line-height:1.8}.lg\:text-xs{font-size:12px;line-height:1.6}.lg\:my-2{margin-top:.5rem;margin-bottom:.5rem}.lg\:mr-0{margin-right:0}.lg\:mt-1{margin-top:.25rem}.lg\:mt-2{margin-top:.5rem}.lg\:mr-2{margin-right:.5rem}.lg\:mr-4{margin-right:1rem}.lg\:mt-5{margin-top:1.25rem}.lg\:mt-6{margin-top:1.5rem}.lg\:mb-6{margin-bottom:1.5rem}.lg\:ml-6{margin-left:1.5rem}.lg\:mt-8{margin-top:2rem}.lg\:mt-10{margin-top:2.5rem}.lg\:max-w-md{max-width:28rem}.lg\:p-6{padding:1.5rem}.lg\:py-2{padding-top:.5rem;padding-bottom:.5rem}.lg\:px-3{padding-left:.75rem;padding-right:.75rem}.lg\:py-4{padding-top:1rem;padding-bottom:1rem}.lg\:px-6{padding-left:1.5rem;padding-right:1.5rem}.lg\:pt-0{padding-top:0}.lg\:pb-2{padding-bottom:.5rem}.lg\:pt-6{padding-top:1.5rem}.lg\:pb-10{padding-bottom:2.5rem}.lg\:pt-16{padding-top:4rem}.lg\:text-center{text-align:center}.lg\:hover\:text-gray-400:hover{--tw-text-opacity:1;color:rgba(156,163,175,var(--tw-text-opacity))}.lg\:w-4{width:1rem}.lg\:w-6{width:1.5rem}.lg\:w-10{width:2.5rem}.lg\:column-count-1{-moz-column-count:1;column-count:1}}.nuxt-progress{position:fixed;top:0;left:0;right:0;height:2px;width:0;opacity:1;transition:width .1s,opacity .4s;background-color:#000;z-index:999999}.nuxt-progress.nuxt-progress-notransition{transition:none}.nuxt-progress-failed{background-color:red}.index{display:block}.icon[data-v-0a938766]{display:block;fill:currentColor}.floating-logo[data-v-1ab1e7a8]{-webkit-animation:floating-data-v-1ab1e7a8 2s ease infinite;animation:floating-data-v-1ab1e7a8 2s ease infinite}@-webkit-keyframes floating-data-v-1ab1e7a8{0%{transform:translateZ(0)}50%{transform:translate3d(0,-30%,0)}to{transform:translateZ(0)}}@keyframes floating-data-v-1ab1e7a8{0%{transform:translateZ(0)}50%{transform:translate3d(0,-30%,0)}to{transform:translateZ(0)}}.floating-logo[data-v-1ab1e7a8]:first-child{-webkit-animation-delay:.15s;animation-delay:.15s}.floating-logo[data-v-1ab1e7a8]:nth-child(2){-webkit-animation-delay:.3s;animation-delay:.3s}.floating-logo[data-v-1ab1e7a8]:nth-child(3){-webkit-animation-delay:.45s;animation-delay:.45s}.floating-logo[data-v-1ab1e7a8]:nth-child(4){-webkit-animation-delay:.6s;animation-delay:.6s}.floating-logo[data-v-1ab1e7a8]:nth-child(5){-webkit-animation-delay:.75s;animation-delay:.75s}.floating-logo[data-v-1ab1e7a8]:nth-child(6){-webkit-animation-delay:.9s;animation-delay:.9s}.floating-logo[data-v-1ab1e7a8]:nth-child(7){-webkit-animation-delay:1.05s;animation-delay:1.05s}.floating-logo[data-v-1ab1e7a8]:nth-child(8){-webkit-animation-delay:1.2s;animation-delay:1.2s}.floating-logo[data-v-1ab1e7a8]:nth-child(9){-webkit-animation-delay:1.35s;animation-delay:1.35s}.floating-logo[data-v-1ab1e7a8]:nth-child(10){-webkit-animation-delay:1.5s;animation-delay:1.5s}.floating-logo[data-v-1ab1e7a8]:nth-child(11){-webkit-animation-delay:1.65s;animation-delay:1.65s}.floating-logo[data-v-1ab1e7a8]:nth-child(12){-webkit-animation-delay:1.8s;animation-delay:1.8s}.floating-logo[data-v-1ab1e7a8]:nth-child(13){-webkit-animation-delay:1.95s;animation-delay:1.95s}.floating-logo[data-v-1ab1e7a8]:nth-child(14){-webkit-animation-delay:2.1s;animation-delay:2.1s}.floating-logo[data-v-1ab1e7a8]:nth-child(15){-webkit-animation-delay:2.25s;animation-delay:2.25s}.floating-logo[data-v-1ab1e7a8]:nth-child(16){-webkit-animation-delay:2.4s;animation-delay:2.4s}.floating-logo[data-v-1ab1e7a8]:nth-child(17){-webkit-animation-delay:2.55s;animation-delay:2.55s}.floating-logo[data-v-1ab1e7a8]:nth-child(18){-webkit-animation-delay:2.7s;animation-delay:2.7s}.floating-logo[data-v-1ab1e7a8]:nth-child(19){-webkit-animation-delay:2.85s;animation-delay:2.85s}.floating-logo[data-v-1ab1e7a8]:nth-child(20){-webkit-animation-delay:3s;animation-delay:3s}.floating-logo[data-v-1ab1e7a8]:nth-child(21){-webkit-animation-delay:3.15s;animation-delay:3.15s}.floating-logo[data-v-1ab1e7a8]:nth-child(22){-webkit-animation-delay:3.3s;animation-delay:3.3s}.floating-logo[data-v-1ab1e7a8]:nth-child(23){-webkit-animation-delay:3.45s;animation-delay:3.45s}.floating-logo[data-v-1ab1e7a8]:nth-child(24){-webkit-animation-delay:3.6s;animation-delay:3.6s}.floating-logo[data-v-1ab1e7a8]:nth-child(25){-webkit-animation-delay:3.75s;animation-delay:3.75s}.floating-logo[data-v-1ab1e7a8]:nth-child(26){-webkit-animation-delay:3.9s;animation-delay:3.9s}.floating-logo[data-v-1ab1e7a8]:nth-child(27){-webkit-animation-delay:4.05s;animation-delay:4.05s}.floating-logo[data-v-1ab1e7a8]:nth-child(28){-webkit-animation-delay:4.2s;animation-delay:4.2s}.floating-logo[data-v-1ab1e7a8]:nth-child(29){-webkit-animation-delay:4.35s;animation-delay:4.35s}.floating-logo[data-v-1ab1e7a8]:nth-child(30){-webkit-animation-delay:4.5s;animation-delay:4.5s}.floating-logo[data-v-1ab1e7a8]:nth-child(31){-webkit-animation-delay:4.65s;animation-delay:4.65s}.floating-logo[data-v-1ab1e7a8]:nth-child(32){-webkit-animation-delay:4.8s;animation-delay:4.8s}.floating-logo[data-v-1ab1e7a8]:nth-child(33){-webkit-animation-delay:4.95s;animation-delay:4.95s}.floating-logo[data-v-1ab1e7a8]:nth-child(34){-webkit-animation-delay:5.1s;animation-delay:5.1s}.floating-logo[data-v-1ab1e7a8]:nth-child(35){-webkit-animation-delay:5.25s;animation-delay:5.25s}.floating-logo[data-v-1ab1e7a8]:nth-child(36){-webkit-animation-delay:5.4s;animation-delay:5.4s}.floating-logo[data-v-1ab1e7a8]:nth-child(37){-webkit-animation-delay:5.55s;animation-delay:5.55s}.floating-logo[data-v-1ab1e7a8]:nth-child(38){-webkit-animation-delay:5.7s;animation-delay:5.7s}.floating-logo[data-v-1ab1e7a8]:nth-child(39){-webkit-animation-delay:5.85s;animation-delay:5.85s}.floating-logo[data-v-1ab1e7a8]:nth-child(40){-webkit-animation-delay:6s;animation-delay:6s}.floating-logo[data-v-1ab1e7a8]:nth-child(41){-webkit-animation-delay:6.15s;animation-delay:6.15s}.floating-logo[data-v-1ab1e7a8]:nth-child(42){-webkit-animation-delay:6.3s;animation-delay:6.3s}.floating-logo[data-v-1ab1e7a8]:nth-child(43){-webkit-animation-delay:6.45s;animation-delay:6.45s}.floating-logo[data-v-1ab1e7a8]:nth-child(44){-webkit-animation-delay:6.6s;animation-delay:6.6s}.floating-logo[data-v-1ab1e7a8]:nth-child(45){-webkit-animation-delay:6.75s;animation-delay:6.75s}.floating-logo[data-v-1ab1e7a8]:nth-child(46){-webkit-animation-delay:6.9s;animation-delay:6.9s}.floating-logo[data-v-1ab1e7a8]:nth-child(47){-webkit-animation-delay:7.05s;animation-delay:7.05s}.floating-logo[data-v-1ab1e7a8]:nth-child(48){-webkit-animation-delay:7.2s;animation-delay:7.2s}.floating-logo[data-v-1ab1e7a8]:nth-child(49){-webkit-animation-delay:7.35s;animation-delay:7.35s}.floating-logos-container[data-v-1ab1e7a8]{width:calc(50% - 5rem)}@-webkit-keyframes left-data-v-2b899a1e{0%{transform:translateZ(0) rotate(180deg)}25%{transform:translate3d(40%,0,0) rotate(180deg)}50%{transform:translateZ(0) rotate(180deg)}to{transform:translateZ(0) rotate(180deg)}}@keyframes left-data-v-2b899a1e{0%{transform:translateZ(0) rotate(180deg)}25%{transform:translate3d(40%,0,0) rotate(180deg)}50%{transform:translateZ(0) rotate(180deg)}to{transform:translateZ(0) rotate(180deg)}}.arrow-animation-left svg[data-v-2b899a1e]{-webkit-animation:left-data-v-2b899a1e 2s ease infinite;animation:left-data-v-2b899a1e 2s ease infinite}@-webkit-keyframes right-data-v-2b899a1e{0%{transform:translateZ(0)}25%{transform:translate3d(-40%,0,0)}50%{transform:translateZ(0)}to{transform:translateZ(0)}}@keyframes right-data-v-2b899a1e{0%{transform:translateZ(0)}25%{transform:translate3d(-40%,0,0)}50%{transform:translateZ(0)}to{transform:translateZ(0)}}.arrow-animation-right svg[data-v-2b899a1e]{-webkit-animation:right-data-v-2b899a1e 2s ease infinite;animation:right-data-v-2b899a1e 2s ease infinite}.clear-button-wrapper[data-v-2b899a1e]{transition:opacity .2s ease .2s,transform .2s ease .2s,max-width .2s ease;max-width:6rem;opacity:1;transform:translateZ(0)}.clear-button-wrapper.is-hidden[data-v-2b899a1e]{opacity:0;transform:translate3d(-25%,0,0);max-width:0;transition:opacity .2s ease,transform .2s ease,max-width .2s ease .2s}.scroller[data-v-2b899a1e]{-ms-overflow-style:none;scrollbar-width:none}.scroller[data-v-2b899a1e]::-webkit-scrollbar{display:none}.app-button[data-v-2b899a1e]:not(:last-child){margin-right:1rem}.project-card[data-v-61b256b6]{-moz-column-break-inside:avoid;break-inside:avoid}@media (max-width:1023px){.project-card .row[data-v-61b256b6]:not(:first-child){margin-top:1rem}}.project-card .row:not(:first-child) td[data-v-61b256b6]{padding-top:.5rem}@media (max-width:1023px){.project-card .row:not(:first-child) td[data-v-61b256b6]{padding-top:0}}.project-card .github-link[data-v-61b256b6]:hover,.project-card .link[data-v-61b256b6]:hover{color:var(--color)}.project-card .description[data-v-61b256b6] li{padding-left:1.8rem;position:relative}.project-card .description[data-v-61b256b6] li:before{position:absolute;left:0;top:0}.project-card .description[data-v-61b256b6] ol{counter-reset:counter}.project-card .description[data-v-61b256b6] ol li{counter-increment:counter}.project-card .description[data-v-61b256b6] ol li:before{content:counter(counter) "."}.project-card .description[data-v-61b256b6] ul li:before{content:"—"}.project-card .description[data-v-61b256b6] :not(:first-child){margin-top:1.1428571429em}.project-card .description[data-v-61b256b6] li:not(:first-child){margin-top:.5em}.project-card .youtube-icon-bg[data-v-61b256b6]{fill:#000;opacity:.75}.project-card .video-block:hover .youtube-icon-bg[data-v-61b256b6]{fill:var(--color);opacity:1}.heart[data-v-af4ccb18]{-webkit-animation:heartbeat-data-v-af4ccb18 2s ease infinite;animation:heartbeat-data-v-af4ccb18 2s ease infinite}@-webkit-keyframes heartbeat-data-v-af4ccb18{0%{transform:scale(.75)}10%{transform:scale(1)}20%{transform:scale(.75)}30%{transform:scale(1)}40%{transform:scale(.75)}50%{transform:scale(.75)}to{transform:scale(.75)}}@keyframes heartbeat-data-v-af4ccb18{0%{transform:scale(.75)}10%{transform:scale(1)}20%{transform:scale(.75)}30%{transform:scale(1)}40%{transform:scale(.75)}50%{transform:scale(.75)}to{transform:scale(.75)}}.suggest-form[data-v-af4ccb18]{width:22rem}</style><link rel="preload" href="/_nuxt/static/1666178784/explainability/state.js" as="script"><link rel="preload" href="/_nuxt/static/1666178784/explainability/payload.js" as="script"><link rel="preload" href="/_nuxt/static/1666178784/manifest.js" as="script">
  </head>
  <body>
    <noscript data-n-head="ssr" data-hid="gtm-noscript" data-pbody="true"><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-53TSBBF&" height="0" width="0" style="display:none;visibility:hidden" title="gtm"></iframe></noscript><div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div><div class="pt-9 lg:pt-6 absolute left-0 top-0 right-0 z-10"><div class="mx-auto px-10 lg:px-6 flex items-center"><div class="flex items-center ml-auto"><a href="https://github.com/aporia-ai/mlops.toys" target="_blank" class="ml-10 lg:ml-6 text-sm lg:text-xs text-gray-400 hover:text-purple-600 transition-colors flex items-center"><svg xmlns="http://www.w3.org/2000/svg" class="w-4 h-4 block mr-3 lg:mr-2 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <span>Contribute</span></a></div></div></div> <div class="pt-24 pb-10 lg:pb-10 lg:pt-16 text-center overflow-hidden transform-gpu bg-gray-50" data-v-1ab1e7a8><div class="mx-auto px-10 lg:px-6 max-w-lg lg:max-w-md" data-v-1ab1e7a8><svg xmlns="http://www.w3.org/2000/svg" class="block w-16 h-16 lg:w-10 lg:h-10 text-aporia mx-auto icon sprite-icons icon icon-logo" data-v-0a938766 data-v-0a938766 data-v-1ab1e7a8><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-logo" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-logo" data-v-0a938766 data-v-0a938766></use></svg> <h1 class="text-3xl lg:text-xl mx-auto font-bold text-gray-900 mt-3" data-v-1ab1e7a8>MLOps.toys</h1> <p class="mt-4 text-lg lg:text-base text-gray-500" data-v-1ab1e7a8>A list of MLOps projects</p> <a type="" href="#projects" class="rounded transition-colors inline-block mt-8 lg:mt-6 px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-purple-600 hover:bg-purple-700" data-v-1ab1e7a8>New projects</a></div> <div class="floating-logos lg:hidden pointer-events-none absolute left-10 right-10 top-24 bottom-14" data-v-1ab1e7a8><div class="floating-logos-container flex flex-col justify-between absolute -left-24 top-0 bottom-0" data-v-1ab1e7a8><div class="floating-logos-row flex items-center w-full justify-around" data-v-1ab1e7a8><div class="floating-logo relative filter rounded flex items-center justify-center w-6 h-6" style="background-color:#eafbfc" data-v-1ab1e7a8><img src="./images/projects/lakefs.svg" alt="lakeFS" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-8 h-8 mb-4" style="background-color:#f5edff" data-v-1ab1e7a8><img src="./images/projects/whylabs.png" alt="WhyLabs" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-10 h-10 mt-1" style="background-color:#fdf1e6" data-v-1ab1e7a8><img src="./images/projects/wandb.png" alt="Weights & Biases" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div></div><div class="floating-logos-row flex items-center w-full justify-around" data-v-1ab1e7a8><div class="floating-logo relative filter rounded flex items-center justify-center w-8 h-8 mb-3" style="background-color:#fde6e3" data-v-1ab1e7a8><img src="./images/projects/valohai.svg" alt="Valohai" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-10 h-10" style="background-color:#e9f4fd" data-v-1ab1e7a8><img src="./images/projects/nvidia.svg" alt="Triton Inference Server" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-8 h-8 mt-1" style="background-color:#e9f4fd" data-v-1ab1e7a8><img src="./images/projects/pytorch.svg" alt="TorchServe" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-6 h-6 mt-1" style="background-color:#e9f4fd" data-v-1ab1e7a8><img src="./images/projects/tensorflow.svg" alt="Tensorflow Serving" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div></div><div class="floating-logos-row flex items-center w-full justify-around" data-v-1ab1e7a8><div class="floating-logo relative filter rounded flex items-center justify-center w-6 h-6 mb-2" style="background-color:#e9f4fd" data-v-1ab1e7a8><img src="./images/projects/syndicai.svg" alt="Syndicai" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-8 h-8 mt-3" style="background-color:#fde6e3" data-v-1ab1e7a8><img src="./images/projects/stoke.png" alt="Stoke" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-10 h-10 mb-4 mr-10" style="background-color:#fde6e3" data-v-1ab1e7a8><img src="./images/projects/spock.png" alt="Spock" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div></div><div class="floating-logos-row flex items-center w-full justify-around px-10" data-v-1ab1e7a8><div class="floating-logo relative filter rounded flex items-center justify-center w-8 h-8 ml-20" style="background-color:#fde6e3" data-v-1ab1e7a8><img src="./images/projects/spell.svg" alt="Spell" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-10 h-10 mt-3 ml-20" style="background-color:#e9f4fd" data-v-1ab1e7a8><img src="./images/projects/seldoncore.svg" alt="Seldon Core" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-6 h-6" style="background-color:#e9f4fd" data-v-1ab1e7a8><img src="./images/projects/sagify.png" alt="Sagify" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div></div></div><div class="floating-logos-container flex flex-col justify-between absolute -right-24 top-0 bottom-0" data-v-1ab1e7a8><div class="floating-logos-row flex items-center w-full justify-around px-10" data-v-1ab1e7a8><div class="floating-logo relative filter rounded flex items-center justify-center w-10 h-10" style="background-color:#fefbed" data-v-1ab1e7a8><img src="./images/projects/shap.svg" alt="SHAP" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-8 h-8" style="background-color:#fde6e3" data-v-1ab1e7a8><img src="./images/projects/primehub.png" alt="PrimeHub" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div></div><div class="floating-logos-row flex items-center w-full justify-around px-6" data-v-1ab1e7a8><div class="floating-logo relative filter rounded flex items-center justify-center w-8 h-8" style="background-color:#fde6e3" data-v-1ab1e7a8><img src="./images/projects/ploomber.svg" alt="Ploomber" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-10 h-10" style="background-color:#eafbfc" data-v-1ab1e7a8><img src="./images/projects/pachyderm.svg" alt="Pachyderm" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-6 h-6" style="background-color:#fde6e3" data-v-1ab1e7a8><img src="./images/projects/orchest.png" alt="Orchest" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div></div><div class="floating-logos-row flex items-center w-full justify-around" data-v-1ab1e7a8><div class="floating-logo relative filter rounded flex items-center justify-center w-6 h-6" style="background-color:#e9f4fd" data-v-1ab1e7a8><img src="./images/projects/ovms.png" alt="OpenVINO™ Model Server" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-8 h-8" style="background-color:#fde6e3" data-v-1ab1e7a8><img src="./images/projects/pai.svg" alt="OpenPAI" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-10 h-10" style="background-color:#fdf1e6" data-v-1ab1e7a8><img src="./images/projects/neptune.svg" alt="Neptune" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-8 h-8" style="background-color:#f5edff" data-v-1ab1e7a8><img src="./images/projects/mlrun.png" alt="MLRun" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div></div><div class="floating-logos-row flex items-center w-full justify-around px-10" data-v-1ab1e7a8><div class="floating-logo relative filter rounded flex items-center justify-center w-10 h-10" style="background-color:#fdf1e6" data-v-1ab1e7a8><img src="./images/projects/mlflow.svg" alt="MLFlow" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-6 h-6" style="background-color:#fde6e3" data-v-1ab1e7a8><img src="./images/projects/kubeflow.svg" alt="Kubeflow" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div><div class="floating-logo relative filter rounded flex items-center justify-center w-8 h-8" style="background-color:#fde6e3" data-v-1ab1e7a8><img src="./images/projects/katonic.png" alt="Katonic.ai" class="block w-7/12 h-7/12" data-v-1ab1e7a8></div></div></div></div></div> <div id="projects" class="projects" data-v-2b899a1e><div class="header my-5 lg:my-2 sticky backdrop-filter backdrop-blur-xl top-0 left-0 w-full z-10 transform-gpu" style="background-color:rgba(255,255,255,.8)" data-v-2b899a1e><div class="py-5 lg:py-4 transform-gpu" data-v-2b899a1e><div class="mx-auto px-10 lg:px-6 flex items-center justify-between lg:block" data-v-2b899a1e><a href="/" class="mr-10 lg:hidden text-gray-400 flex items-center hover:text-aporia flex-shrink-0 transform transform-gpu transition-all translate-x-4 opacity-0 pointer-events-none" data-v-2b899a1e><svg xmlns="http://www.w3.org/2000/svg" class="block w-8 h-8 lg:hidden icon sprite-icons icon icon-logo" data-v-0a938766 data-v-0a938766 data-v-2b899a1e><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-logo" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-logo" data-v-0a938766 data-v-0a938766></use></svg> <div class="ml-4" data-v-2b899a1e><div class="text-xl font-bold" data-v-2b899a1e>MLOps.toys</div> <div class="text-xs text-gray-400 text-right -mt-1.5" data-v-2b899a1e>by Aporia</div></div></a> <div class="relative overflow-hidden" data-v-2b899a1e><div class="scroller overflow-x-auto" data-v-2b899a1e><div class="flex items-center flex-nowrap justify-start" data-v-2b899a1e><div class="clear-button-wrapper overflow-hidden flex-shrink-0" data-v-2b899a1e><a href="/" type="button" class="group whitespace-nowrap text-xs mr-4 pr-2 flex-shrink-0 nuxt-link-active" data-v-2b899a1e><div class="flex items-center" data-v-2b899a1e><div class="border border-solid border-gray-200 flex-shrink-0 p-1 rounded mr-2 flex items-center group-hover:border-purple-300 transition-colors" data-v-2b899a1e><svg xmlns="http://www.w3.org/2000/svg" class="w-2 h-2 block text-gray-400 group-hover:text-purple-600 transition-colors flex-shrink-0 icon sprite-icons icon icon-cross" data-v-0a938766 data-v-0a938766 data-v-2b899a1e><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-cross" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-cross" data-v-0a938766 data-v-0a938766></use></svg></div> <span class="text-gray-400 group-hover:text-purple-600 transition-colors flex-shrink-0" data-v-2b899a1e>Clear</span></div></a></div> <button type="button" class="rounded transition-colors app-button flex-shrink-0 border border-solid border-gray-200 px-3 py-2 text-xs font-medium text-gray-500 hover:bg-gray-50" data-v-2b899a1e>
								Training Orchestration
							</button><button type="button" class="rounded transition-colors app-button flex-shrink-0 border border-solid border-gray-200 px-3 py-2 text-xs font-medium text-gray-500 hover:bg-gray-50" data-v-2b899a1e>
								Model Monitoring
							</button><button type="button" class="rounded transition-colors app-button flex-shrink-0 border border-solid border-gray-200 px-3 py-2 text-xs font-medium text-gray-500 hover:bg-gray-50" data-v-2b899a1e>
								Model Testing
							</button><button type="button" class="rounded transition-colors app-button flex-shrink-0 border border-solid border-gray-200 px-3 py-2 text-xs font-medium text-gray-500 hover:bg-gray-50" data-v-2b899a1e>
								Model Serving
							</button><button type="button" class="rounded transition-colors app-button flex-shrink-0 border border-solid border-gray-200 px-3 py-2 text-xs font-medium text-gray-500 hover:bg-gray-50" data-v-2b899a1e>
								Data Versioning
							</button><button type="button" class="rounded transition-colors app-button flex-shrink-0 border border-solid border-gray-200 px-3 py-2 text-xs font-medium text-gray-500 hover:bg-gray-50" data-v-2b899a1e>
								Feature Store
							</button><button type="button" class="rounded transition-colors app-button flex-shrink-0 border border-solid border-gray-200 px-3 py-2 text-xs font-medium text-gray-500 hover:bg-gray-50" data-v-2b899a1e>
								Experiment Tracking
							</button><button type="button" class="rounded transition-colors app-button flex-shrink-0 border border-solid border-gray-200 px-3 py-2 text-xs font-medium text-gray-500 hover:bg-gray-50" style="background-color:#fefdf6;color:#f6e278;border-color:transparent" data-v-2b899a1e>
								Explainability
							</button></div></div> <button type="button" class="absolute left-0 top-0 bottom-0 bg-gradient-to-l from-transparent to-white items-center justify-center pr-12 z-10 transition-all duration-200 arrow-animation-left flex text-gray-400 hover:text-purple-600 lg:hover:text-gray-400 opacity-0 pointer-events-none" data-v-2b899a1e><svg xmlns="http://www.w3.org/2000/svg" class="w-3 h-3 block transform rotate-180 icon sprite-icons icon icon-arrow" data-v-0a938766 data-v-0a938766 data-v-2b899a1e><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-arrow" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-arrow" data-v-0a938766 data-v-0a938766></use></svg></button> <button type="button" class="absolute right-0 top-0 bottom-0 bg-gradient-to-r from-transparent to-white items-center justify-center pl-12 z-10 transition-all duration-200 arrow-animation-right flex text-gray-400 hover:text-purple-600 lg:hover:text-gray-400" data-v-2b899a1e><svg xmlns="http://www.w3.org/2000/svg" class="w-3 h-3 block transform icon sprite-icons icon icon-arrow" data-v-0a938766 data-v-0a938766 data-v-2b899a1e><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-arrow" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-arrow" data-v-0a938766 data-v-0a938766></use></svg></button></div></div></div></div> <div class="mx-auto px-10 lg:px-6 max-w-screen cards -mb-6 transition-all transform opacity-0 translate-y-5" data-v-2b899a1e><div style="display:-webkit-box;display:-ms-flexbox;display:flex;margin-left:0" data-v-2b899a1e><div style="box-sizing:border-box;background-clip:padding-box;width:50%;border:0 solid transparent;border-left-width:0"><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f7fdfe;--color:#60DFE8" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/treeverse/lakeFS" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/lakefs.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/treeverse/lakeFS" target="_blank" class="link transition-colors" data-v-61b256b6>lakeFS</a></h3> <a href="https://github.com/treeverse/lakeFS" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Data Versioning
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>lakeFS is an open-source data lake management platform that transforms your object storage into a Git-like repository. lakeFS enables you to manage your data lake the way you manage your code. Run parallel pipelines for experimentation and CI/CD for your data.<br>
Features:</p>
<ul>
<li><strong>Scalable:</strong> Version control data at exabyte scale.</li>
<li><strong>Flexible:</strong> Run git operations like branch, commit, and  merge over your data in any storage service.</li>
<li><strong>Develop Faster:</strong> Zero copy branching for frictionless experimentation, easy collaboration.</li>
<li><strong>Enable Clean Workflows:</strong> Use pre-commit & merge hooks for CI/CD workflows.</li>
<li><strong>Resilient:</strong> Recover from data issues faster with revert capability.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/xThorxDzmrw" title="lakeFS Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/treeverse/lakeFS" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try lakeFS!
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fefaf5;--color:#F09240" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://wandb.ai/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/wandb.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://wandb.ai/" target="_blank" class="link transition-colors" data-v-61b256b6>Weights & Biases</a></h3> <a href="https://github.com/wandb/client" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Experiment Tracking
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Track and visualize all the pieces of your machine learning pipeline, from datasets to production models.</p>
<ul>
<li>Quickly identify model regressions. Use W&B to visualize results in real time, all in a central dashboard.</li>
<li>Focus on the interesting ML. Spend less time manually tracking results in spreadsheets and text files.</li>
<li>Capture dataset versions with W&B Artifacts to identify how changing data affects your resulting models.</li>
<li>Reproduce any model, with saved code, hyperparameters, launch commands, input data, and resulting model weights.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/91HhNtmb0B4" title="Weights & Biases Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://wandb.ai/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Weights & Biases
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f6fbfe;--color:#53a7ee" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://developer.nvidia.com/nvidia-triton-inference-server" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/nvidia.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://developer.nvidia.com/nvidia-triton-inference-server" target="_blank" class="link transition-colors" data-v-61b256b6>Triton Inference Server</a></h3> <a href="https://github.com/triton-inference-server/server" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Serving
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Works well with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Azure ML</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Google CAIP</span> <!----></div></div></td></tr> <tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Competes with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Tensorflow Serving</span> <!----></div><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>TorchServe</span> <!----></div></div></td></tr></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Triton Inference Server simplifies the deployment of AI models at scale in production.</p>
<ul>
<li>Supports TensorFlow, TensorRT, PyTorch, ONNX Runtime, and custom framework backends.</li>
<li>Triton runs models concurrently on GPUs to maximize utilization, supports CPU-based inferencing, and offers advanced features like model ensemble and streaming inferencing.</li>
<li>Available as a Docker container, Triton integrates with Kubernetes for orchestration and scaling.</li>
<li>Can be used with cloud AI platforms like Azure ML and Google CAIP.</li>
<li>Triton exports Prometheus metrics for monitoring.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/1DUqD3zMwB4" title="Triton Inference Server Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://developer.nvidia.com/nvidia-triton-inference-server" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Triton
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f6fbfe;--color:#53a7ee" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/tensorflow/serving" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/tensorflow.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/tensorflow/serving" target="_blank" class="link transition-colors" data-v-61b256b6>Tensorflow Serving</a></h3> <a href="https://github.com/tensorflow/serving" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Serving
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><!----> <tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Competes with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Triton Inference Server</span> <!----></div></div></td></tr></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>TensorFlow Serving is a flexible, high-performance serving system for TF models, designed for production environments.</p>
<ul>
<li>Can serve multiple models, or multiple versions of the same model simultaneously.</li>
<li>Exposes both gRPC as well as HTTP inference endpoints.</li>
<li>Allows deployment of new model versions without changing any client code.</li>
<li>Supports canarying new versions and A/B testing experimental models.</li>
<li>Adds minimal latency to inference time due to efficient, low-overhead implementation.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/q_IkJcPyNl0" title="Tensorflow Serving Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/tensorflow/serving" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Tensorflow Serving
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/fidelity/stoke" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/stoke.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/fidelity/stoke" target="_blank" class="link transition-colors" data-v-61b256b6>Stoke</a></h3> <a href="https://github.com/fidelity/stoke" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><!----> <tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Competes with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>HuggingFace Accelerate</span> <!----></div><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>PyTorch Lightning (Accelerate)</span> <!----></div></div></td></tr></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>stoke is a lightweight wrapper for PyTorch that provides a simple declarative API for context switching between devices (e.g. CPU, GPU), distributed modes, mixed-precision, and PyTorch extensions. This allows you to switch from local full-precision CPU to mixed-precision distributed multi-GPU with extensions (like optimizer state sharding) by simply changing a few declarative flags. Additionally, stoke exposes configuration settings for every underlying backend for those that want configurability and raw access to the underlying libraries. In short, stoke is the best of PyTorch Lightning Accelerators disconnected from the rest of PyTorch Lightning. Write whatever PyTorch code you want, but leave device and backend context switching to stoke.<br>
Supports:</p>
<ul>
<li><strong>Devices:</strong> CPU, GPU, multi-GPU</li>
<li><strong>Distributed:</strong> DDP, Horovod, deepspeed (via DDP)</li>
<li><strong>Mixed-Precision:</strong> AMP, Nvidia Apex, deepspeed (custom APEX like backend)</li>
<li><strong>Extensions:</strong> fairscale (Optimizer State Sharding and Sharded DDP), deepspeed (ZeRO Stage 0-3, etc.)</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/fidelity/stoke" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Stoke
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://spell.ml/pricing" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/spell.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://spell.ml/pricing" target="_blank" class="link transition-colors" data-v-61b256b6>Spell</a></h3> <!----></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Works well with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Jupyter Notebooks</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Kubernetes</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Grafana</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Weights and Biases</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Arize</span> <!----></div></div></td></tr> <!----></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Spell is an <strong>end-to-end deep learning platform</strong> that automates complex ML infrastructure and operational work required to train and deploy AI models. Spell is fully hybrid-cloud, and can deploy easily into any cloud or on-prem hardware.</p>
<ul>
<li><strong>Run Orchestration:</strong> Automate cloud training execution from a user's local CLI as a tracked and reproducible experiment, capturing all outputs and comprehensive metrics.</li>
<li><strong>Model Serving:</strong> Serve models directly into production from a model registry, complete with lineage metadata, backed by a managed Kubernetes cluster for maximum scalability and robustness.</li>
<li><strong>Experiment Management:</strong> Manage, organize, collaborate on, and visualize your entire ML training portfolio in the cloud, under one centralized control pane.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/s2E5sfmEbec" title="Spell Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://spell.ml/pricing" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Spell
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f6fbfe;--color:#53a7ee" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://www.sagifyml.com/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/sagify.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://www.sagifyml.com/" target="_blank" class="link transition-colors" data-v-61b256b6>Sagify</a></h3> <a href="https://github.com/Kenza-AI/sagify" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Serving
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>A command-line utility to train and deploy Machine Learning and Deep Learning models on AWS SageMaker in a few simple steps.</p>
<p>Key features:</p>
<ol>
<li><strong>Turn on ML superpowers:</strong> Train, tune and deploy hundreds of ML models by implementing just 2 functions</li>
<li><strong>Focus 100% on Machine Learning:</strong> Manage your ML models from one place without dealing with low level engineering tasks</li>
<li><strong>100% reliable:</strong> No more flaky ML pipelines. Sagify offers 100% reliable training and deployment on AWS.</li>
</ol>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://www.sagifyml.com/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Sagify
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/InfuseAI/primehub" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/primehub.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/InfuseAI/primehub" target="_blank" class="link transition-colors" data-v-61b256b6>PrimeHub</a></h3> <a href="https://github.com/InfuseAI/primehub" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>PrimeHub, an open-source pluggable MLOps platform on the top of Kubernetes for teams of data scientists and administrators. PrimeHub equips enterprises with consistent yet flexible tools to develop, train, and deploy ML models at scale. By improving the iterative process of data science, data teams can collaborate closely and innovate fast.</p>
<ul>
<li>Cluster Computing with multi-tenancy</li>
<li>One-Click Notebook Environments</li>
<li>Group-centric Datasets Management / Resources Management / Access-control Management</li>
<li>Custom Machine Learning Environments with Image Builder</li>
<li>Model Tracking and Deployment</li>
<li>Capability Augmentation with 3rd-party Apps Store</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/3ZOPXR9L2Ho" title="PrimeHub Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/InfuseAI/primehub" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try PrimeHub
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f7fdfe;--color:#60DFE8" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://www.pachyderm.com/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/pachyderm.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://www.pachyderm.com/" target="_blank" class="link transition-colors" data-v-61b256b6>Pachyderm</a></h3> <a href="https://github.com/pachyderm/pachyderm" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Data Versioning
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Pachyderm is a tool for version-controlled, automated, end-to-end data pipelines for data science.</p>
<p>Features:</p>
<ul>
<li><strong>Containerized</strong>: Pachyderm is built on Docker and Kubernetes. Whatever languages or libraries your pipeline needs, they can run on Pachyderm which can easily be deployed on any cloud provider or on prem.</li>
<li><strong>Version Control</strong>: Pachyderm version controls your data as it's processed. You can always ask the system how data has changed, see a diff, and, if something doesn't look right, revert.</li>
<li><strong>Provenance</strong> (aka data lineage): Pachyderm tracks where data comes from. Pachyderm keeps track of all the code and data that created a result.</li>
<li><strong>Parallelization</strong>: Pachyderm can efficiently schedule massively parallel workloads.</li>
<li><strong>Incremental Processing</strong>: Pachyderm understands how your data has changed and is smart enough to only process the new data.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/r9CrtAtuJDI" title="Pachyderm Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://www.pachyderm.com/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Pachyderm
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f6fbfe;--color:#53a7ee" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/openvinotoolkit/model_server" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/ovms.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/openvinotoolkit/model_server" target="_blank" class="link transition-colors" data-v-61b256b6>OpenVINO™ Model Server</a></h3> <a href="https://github.com/openvinotoolkit/model_server" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Serving
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><!----> <tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Competes with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Triton Inference Server</span> <!----></div><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Tensorflow Serving</span> <!----></div><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>TorchServe</span> <!----></div></div></td></tr></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>OpenVINO™ Model Server (OVMS) is a scalable, high-performance solution for serving machine learning models optimized for Intel® architectures.</p>
<ul>
<li>Simultanous serving of any model trained in a framework that is supported by OpenVINO</li>
<li>The server implements gRPC and REST API framework with data serialization and deserialization using TensorFlow Serving API</li>
<li>Uses OpenVINO™ as the inference execution provider</li>
<li>Supports different file systems: local (e.g. NFS), Google Cloud Storage (GCS), Amazon S3, Minio or Azure Blob Storage</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/AfytPrAVdfc" title="OpenVINO™ Model Server Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/openvinotoolkit/model_server" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try OpenVINO™ Model Server
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fefaf5;--color:#F09240" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://neptune.ai/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/neptune.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://neptune.ai/" target="_blank" class="link transition-colors" data-v-61b256b6>Neptune</a></h3> <a href="https://github.com/neptune-ai/neptune-client" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Experiment Tracking
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Neptune is a lightweight experiment logging/tracking tool that helps you with your machine learning experiments.</p>
<p>Features:</p>
<ul>
<li>Rich experiment logging and tracking capabilities</li>
<li>Python and R clients</li>
<li>Experiments dashboards, views and comparison features</li>
<li>Team management</li>
<li>25+ integrations with popular data science stack libraries</li>
<li>Fast, reliable UI</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/w9S5srkfSI4" title="Neptune Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://neptune.ai/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Neptune
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fefaf5;--color:#F09240" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://mlflow.org/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/mlflow.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://mlflow.org/" target="_blank" class="link transition-colors" data-v-61b256b6>MLFlow</a></h3> <a href="https://github.com/mlflow/mlflow" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Experiment Tracking
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>MLflow is a platform to streamline machine learning development, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models.</p>
<p>It offers a set of lightweight APIs that can be used with any existing machine learning application or library (TensorFlow, PyTorch, XGBoost, etc), wherever you currently run ML code (e.g your notebook)</p>
<p>Features:</p>
<ul>
<li><strong>MLflow Tracking:</strong> An API to log parameters, code, and results in machine learning experiments and compare them using an interactive UI.</li>
<li><strong>MLflow Projects:</strong> A code packaging format for reproducible runs using Conda and Docker, so you can share your ML code with others.</li>
<li><strong>MLflow Models:</strong> A model packaging format and tools that let you easily deploy the same model (from any ML library) to batch and real-time scoring on platforms such as Docker, Apache Spark, Azure ML and AWS SageMaker.</li>
<li><strong>MLflow Model Registry:</strong> A centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of MLflow Models.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/VokAGy8C6K4" title="MLFlow Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://mlflow.org/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try MLFlow
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://www.kubeflow.org/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/kubeflow.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://www.kubeflow.org/" target="_blank" class="link transition-colors" data-v-61b256b6>Kubeflow</a></h3> <a href="https://github.com/kubeflow/kubeflow" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>The Kubeflow project is dedicated to making deployments of machine learning (ML) workflows on Kubernetes simple, portable and scalable.</p>
<p>Kubeflow's goal is not to recreate other services, but to provide a straightforward way to deploy best-of-breed open-source systems for ML to diverse infrastructures.</p>
<p>Anywhere you are running Kubernetes, you should be able to run Kubeflow.</p>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/cTZArDgbIWw" title="Kubeflow Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://www.kubeflow.org/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Kubeflow
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f6fbfe;--color:#53a7ee" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/kubeflow/kfserving" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/kubeflow.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/kubeflow/kfserving" target="_blank" class="link transition-colors" data-v-61b256b6>KFServing</a></h3> <a href="https://github.com/kubeflow/kfserving" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Serving
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><!----> <tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Competes with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Seldon Core</span> <!----></div><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle mr-2" data-v-61b256b6>BentoML</span> <span class="text-xs align-middle text-gray-500" data-v-61b256b6>to some extent</span></div></div></td></tr></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>KFServing enables serverless inferencing on Kubernetes to solve production model serving use cases.</p>
<ul>
<li>Provides performant, high abstraction interfaces for common ML frameworks like TensorFlow, XGBoost, scikit-learn, PyTorch, and ONNX.</li>
<li>Provides a Kubernetes Custom Resource Definition (CRD) for serving ML models.</li>
<li>Encapsulate the complexity of autoscaling, networking, health checking, and server configuration to bring cutting edge serving features like GPU autoscaling, scale to zero, and canary rollouts to your ML deployments.</li>
<li>Enable a simple, pluggable, and complete story for your production ML inference server by providing prediction, pre-processing, post-processing and explainability out of the box.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/lj_X2ND2BBI" title="KFServing Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/kubeflow/kfserving" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try KFServing
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f5fdfa;--color:#39DAA3" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://www.iguazio.com/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/iguazio.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://www.iguazio.com/" target="_blank" class="link transition-colors" data-v-61b256b6>Iguazio Data Science Platform</a></h3> <!----></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Feature Store
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>The Iguazio Data Science Platform accelerates and scales development, deployment and management of your AI applications with MLOps and end-to-end automation of machine learning pipelines. The platform includes an online and offline feature store, fully integrated with automated model monitoring and drift detection, model serving and dynamic scaling capabilities, all packaged in an open and managed platform.</p>
<ul>
<li><strong>Ingest Data from Any Source and Build Reusable Online and Offline Features:</strong> Ingest and unify unstructured and structured data in real-time and create online and offline features using Iguazio’s <strong>Integrated Feature Store</strong>.</li>
<li><strong>Continuously Train and Evaluate Models at Scale:</strong> Run experimentation over scalable serverless ML/DL runtimes with automated tracking, data versioning, and continuous integration/delivery (CI/CD) support.</li>
<li><strong>Deploy Models to Production in Seconds:</strong> Deploy models and APIs from a Jupyter notebook or IDE to production in just a few clicks and continuously monitor model performance and mitigate model drift.</li>
<li><strong>Monitor Your Models and Data on the Fly:</strong> Manage, govern and monitor your models and real-time features in production with a simple dashboard integrated with Iguazio’s Feature Store.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/BzQQ1X4LgcQ" title="Iguazio Data Science Platform Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://www.iguazio.com/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Iguazio
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f5fdfa;--color:#39DAA3" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://www.hopsworks.ai/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/hopsworks.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://www.hopsworks.ai/" target="_blank" class="link transition-colors" data-v-61b256b6>Hopsworks</a></h3> <a href="https://github.com/logicalclocks/hopsworks" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Feature Store
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><!----> <tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Competes with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Tecton</span> <!----></div><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Feast</span> <!----></div></div></td></tr></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>The Hopsworks Feature Store manages your features for training and serving models.</p>
<ul>
<li>Provides scale-out storage for training and batch inference as well as low-latency storage for online applications that need to build feature vectors to make real-time predictions.</li>
<li>Provides Python and Java/Scala APIs to enable Batch and Online applications manage and use features for machine learning.</li>
<li>Integrates seamlessly with popular platforms for Data Science, such as AWS Sagemaker and Databricks. It also integrates with backend datalakes, such as S3 and Hadoop.</li>
<li>Supports both cloud and on-prem deployments.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/uVBeoeENEcI" title="Hopsworks Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://www.hopsworks.ai/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Hopsworks
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fffef8;--color:#F6E278" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://www.fiddler.ai/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/fiddler.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://www.fiddler.ai/" target="_blank" class="link transition-colors" data-v-61b256b6>Fiddler</a></h3> <!----></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Explainability
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Continuously monitor, explain, and analyze AI systems at scale. With actionable insights build trustworthy, fair, and responsible AI monitoring.</p>
<ul>
<li>Complex AI systems are inherently black boxes with minimal insight into their operation.</li>
<li>Explainable AI or XAI makes these AI black boxes more like AI glass-boxes by enabling users to always understand the ‘why’ behind their decisions.</li>
<li>Identify, address, and share performance gaps and biases quickly for AI validation and debugging</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/gqnDqrIzabw" title="Fiddler Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://www.fiddler.ai/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Fiddler
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fbf8ff;--color:#AF72FD" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://evidentlyai.com/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/evidentlyai.ico" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://evidentlyai.com/" target="_blank" class="link transition-colors" data-v-61b256b6>Evidently AI</a></h3> <!----></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Monitoring
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Evidently helps analyze machine learning models during validation or production monitoring. It generates interactive reports from pandas DataFramesor csv files.</p>
<p>Features:</p>
<ul>
<li><strong>Model Health:</strong> Quickly visualize model performance and important metrics. Get a prioritized list of issues to debug.</li>
<li><strong>Data Drift:</strong> Compare recent data with the past. Learn which features changed and if key models drivers shifted. Visually explore and understand drift.</li>
<li><strong>Target Drift:</strong> Understand how model predictions and target change over time. If the ground truth is delayed, catch the model decay in advance.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/2suSzXlY_7Y" title="Evidently AI Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://evidentlyai.com/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Evidently AI
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://determined.ai/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/determined.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://determined.ai/" target="_blank" class="link transition-colors" data-v-61b256b6>Determined</a></h3> <a href="https://github.com/determined-ai/determined" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Determined is an open-source deep learning training platform that makes building models fast and easy.</p>
<ul>
<li>Train models faster using state-of-the-art distributed training, without changing your model code</li>
<li>Automatically find high-quality models with advanced hyperparameter tuning from the creators of Hyperband</li>
<li>Get more from your GPUs with smart scheduling and cut cloud GPU costs by seamlessly using preemptible instances</li>
<li>Track and reproduce your work with experiment tracking that works out-of-the-box, covering code versions, metrics, checkpoints, and hyperparameters</li>
</ul>
<p>Determined integrates these features into an easy-to-use, high-performance deep learning environment — which means you can spend your time building models instead of managing infrastructure.</p>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://determined.ai/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Determined
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f7fdfe;--color:#60DFE8" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://dvc.org/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/dvc.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://dvc.org/" target="_blank" class="link transition-colors" data-v-61b256b6>DVC</a></h3> <a href="https://github.com/iterative/dvc" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Data Versioning
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>DVC is an open-source tool for data science and machine learning projects.</p>
<p>Key features:</p>
<ol>
<li>Simple command line Git-like experience. Does not require installing and maintaining any databases. Does not depend on any proprietary online services.</li>
<li>Management and versioning of datasets and machine learning models. Data is saved in S3, Google cloud, Azure, Alibaba cloud, SSH server, HDFS, or even local HDD RAID.</li>
<li>Makes projects reproducible and shareable; helping to answer questions about how a model was built.</li>
<li>Helps manage experiments with Git tags/branches and metrics tracking.</li>
</ol>
<p>DVC aims to replace spreadsheet and document sharing tools (such as Excel or Google Docs) which are being used frequently as both knowledge repositories and team ledgers. DVC also replaces both ad-hoc scripts to track, move, and deploy different model versions; as well as ad-hoc data file suffixes and prefixes.</p>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://dvc.org/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try DVC
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f6fbfe;--color:#53a7ee" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://cortex.dev/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/cortex.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://cortex.dev/" target="_blank" class="link transition-colors" data-v-61b256b6>Cortex</a></h3> <a href="https://github.com/cortexlabs/cortex" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Serving
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Cortex makes it simple to deploy machine learning models in production.</p>
<p><strong>Deploy</strong></p>
<ul>
<li>Deploy TensorFlow, PyTorch, ONNX, scikit-learn, and other models.</li>
<li>Define preprocessing and postprocessing steps in Python.</li>
<li>Configure AP/Is as realtime or batch.</li>
<li>Deploy multiple models per API.</li>
</ul>
<p><strong>Manage</strong></p>
<ul>
<li>Monitor API performance and track predictions.</li>
<li>Update APIs with no downtime.</li>
<li>Stream logs from APIs.</li>
<li>Perform A/B tests.</li>
</ul>
<p><strong>Scale</strong></p>
<ul>
<li>Test locally, scale on your AWS account.</li>
<li>Autoscale to handle production traffic.</li>
<li>Reduce cost with spot instances.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://cortex.dev/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Cortex
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fefaf5;--color:#F09240" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://clear.ml/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/clearml.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://clear.ml/" target="_blank" class="link transition-colors" data-v-61b256b6>ClearML</a></h3> <a href="https://github.com/allegroai/clearml" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Experiment Tracking
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>ClearML is an open source suite of tools that automates preparing, executing, and analyzing machine learning experiments.</p>
<p>Features:</p>
<ul>
<li><strong>ClearML Experiment:</strong> A complete experiment management toolset. Keep track of parameters, jobs, artifacts, metrics, debug data, metadata, and log it all in one clear interface.</li>
<li><strong>ClearML Orchestrate:</strong> The easiest way to manage scheduling and orchestration for GPU / CPU resources and to auto-scale on cloud & on-prem machines. Replicate your dev environment for training anywhere or develop on remote VMs.</li>
<li><strong>ClearML Feature Store:</strong> Data analysis versioning & lineage for full reproducibility. Build and automate data pipelines for R&D and production. Rebalance, debias and mix & match datasets for fine grain control of your data.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/Y5tPfUm9Ghg" title="ClearML Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://clear.ml/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try ClearML
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f5fdfa;--color:#39DAA3" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://www.bytehub.ai/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/default.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://www.bytehub.ai/" target="_blank" class="link transition-colors" data-v-61b256b6>Bytehub</a></h3> <a href="https://github.com/bytehub-ai/bytehub" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Feature Store
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>An easy-to-use feature store.</p>
<p>The Bytehub Feature Store is designed to:</p>
<ul>
<li>Be simple to use, with a Pandas-like API;</li>
<li>Require no complicated infrastructure, running on a local Python installation or in a cloud environment;</li>
<li>Be optimised towards timeseries operations, making it highly suited to applications such as those in finance, energy, forecasting; and</li>
<li>Support simple time/value data as well as complex structures, e.g. dictionaries.</li>
</ul>
<p>It is built on Dask to support large datasets and cluster compute environments.</p>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/ucAlzaJoqeU" title="Bytehub Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://www.bytehub.ai/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Bytehub
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f6fbfe;--color:#53a7ee" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/bodywork-ml/bodywork-core/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/bodywork.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/bodywork-ml/bodywork-core/" target="_blank" class="link transition-colors" data-v-61b256b6>Bodywork</a></h3> <a href="https://github.com/bodywork-ml/bodywork-core/" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Serving
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Bodywork deploys machine learning projects developed in Python, to Kubernetes. It helps you:</p>
<ul>
<li>serve models as microservices</li>
<li>execute batch jobs</li>
<li>run reproducible pipelines</li>
</ul>
<p>On demand, or on a schedule. It automates repetitive DevOps tasks and frees machine learning engineers to focus on what they do best - solving data problems with machine learning.</p>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/bodywork-ml/bodywork-core/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Bodywork
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fbf8ff;--color:#AF72FD" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://aporia.com/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/aporia-logo.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://aporia.com/" target="_blank" class="link transition-colors" data-v-61b256b6>Aporia</a></h3> <!----></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Monitoring
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>With Aporia data scientists and ML engineers can easily build monitoring for their ML models running in production.</p>
<p>Features:</p>
<ul>
<li><strong>Build your own monitors</strong>: Easily define monitoring logic.</li>
<li><strong>Concept drift & Data integrity detections</strong>: Built-in monitors and alerts for prediction drift, data drift, data integrity issues and more.</li>
<li><strong>Runs on your VPC</strong>: Natively supports on-prem and cloud deployments.</li>
<li><strong>User-friendly & flexible</strong>: A simple, intuitive dashboard for all your models in production.</li>
<li><strong>Data segments</strong>: Define & monitor slices of data based on selected features.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/9oyZDXrmWMA" title="Aporia Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://aporia.com/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Aporia
		</a></div></div></div><div style="box-sizing:border-box;background-clip:padding-box;width:50%;border:0 solid transparent;border-left-width:0"><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fbf8ff;--color:#AF72FD" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://whylabs.ai/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/whylabs.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://whylabs.ai/" target="_blank" class="link transition-colors" data-v-61b256b6>WhyLabs</a></h3> <a href="https://github.com/whylabs/whylogs" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Monitoring
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>The WhyLabs Observability Platform enables any AI practitioner to set up AI monitoring in three easy steps. It follows the standard DevOps model of installing a lightweight logging agent (whylogs) alongside your model and sending data profiles to a fully self-service SaaS platform (WhyLabs). On the platform, you can analyze your profiles to see how your model is performing and get automatically get alerted on changes. The platform includes:</p>
<ul>
<li><strong>An easy setup flow</strong> so that you can start getting value right away</li>
<li><strong>Automatic data drift detection and alerting</strong> to prevent model performance degradation</li>
<li><strong>Industry standard for data profiling</strong> enabled by the open source "whylogs" library</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/UsDsLEpigBw" title="WhyLabs Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://whylabs.ai/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try WhyLabs for Free
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://valohai.com/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/valohai.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://valohai.com/" target="_blank" class="link transition-colors" data-v-61b256b6>Valohai</a></h3> <!----></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Valohai is an MLOps platform that handles machine orchestration, automatic reproducibility and deployment.</p>
<ul>
<li><strong>Technology agnostic:</strong> Valohai runs everything in Docker containers so that you can run almost anything on it.</li>
<li><strong>Runs on any cloud:</strong> Valohai natively supports Azure, AWS, GCP and OpenStack.</li>
<li><strong>API, CLI, GUI and Jupyter integration:</strong> Valohai integrates to almost any workflow through its many interfaces.</li>
<li><strong>Managed service:</strong> Seasoned DevOps engineers manage Valohai – so you don’t have to be one.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/jnrSd2nqCWg" title="Valohai Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://valohai.com/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Valohai
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f6fbfe;--color:#53a7ee" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://pytorch.org/serve/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/pytorch.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://pytorch.org/serve/" target="_blank" class="link transition-colors" data-v-61b256b6>TorchServe</a></h3> <a href="https://github.com/pytorch/pytorch" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Serving
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><!----> <tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Competes with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Triton Inference Server</span> <!----></div></div></td></tr></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>TorchServe is a flexible and easy to use tool for serving PyTorch models.</p>
<ul>
<li>With TorchServe, PyTorch users can bring their models to production quicker, without having to write custom code: on top of providing a low latency prediction API, TorchServe embeds default handlers for the most common applications such as object detection and text classification.</li>
<li>TorchServe includes multi-model serving, model versioning for A/B testing, monitoring metrics, and RESTful endpoints for application integration.</li>
<li>TorchServe supports any machine learning environment, including Amazon SageMaker, container services, and Amazon Elastic Compute Cloud (EC2).</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/9lMMCwVhPpo" title="TorchServe Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://pytorch.org/serve/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try TorchServe
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f6fbfe;--color:#53a7ee" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://syndicai.co" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/syndicai.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://syndicai.co" target="_blank" class="link transition-colors" data-v-61b256b6>Syndicai</a></h3> <!----></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Serving
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Works well with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Kubernetes</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Grafana</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Nvidia Triton</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Intel OpenVINO</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>MLFLow</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>ClearML</span> <!----></div></div></td></tr> <!----></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Syndicai is a cloud platform that deploys, manages, and scales any trained AI model in minutes with no configuration & infrastructure setup.</p>
<ul>
<li><strong>Easy to use</strong> - You don't need to know to understand Docker & Kubernetes. Platform Production-ready deployments from day one.</li>
<li><strong>Highly flexible</strong> - Customize every single step of the whole AI model deployment workflow (from model wrappers to Kubernetes configuration manifests), and integrate with tools you love.</li>
<li><strong>Optimized for ML</strong> - Run workload on highly optimized, cost-efficient, and secure infrastructure built specifically for high-performance ML models.</li>
<li><strong>Cloud, Framework agnostic</strong> - Deploy ML models written in frameworks you love and run them on the cloud you want with no extensive and time-consuming setup.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://syndicai.co" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Syndicai
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/fidelity/spock" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/spock.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/fidelity/spock" target="_blank" class="link transition-colors" data-v-61b256b6>Spock</a></h3> <a href="https://github.com/fidelity/spock" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><!----> <tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Competes with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Hydra</span> <!----></div></div></td></tr></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>spock is a framework that helps manage complex parameter configurations during research and development of Python applications. spock lets you focus on the code you need to write instead of re-implementing boilerplate code like creating ArgParsers, reading configuration files, implementing traceability etc. In short, spock configurations are defined by simple and familiar class-based structures. This allows spock to support inheritance, read from multiple markdown formats, and allow hierarchical configuration by composition.<br>
Features:</p>
<ul>
<li><strong>Simple Declaration:</strong> Type checked parameters are defined within a @spock decorated class. Supports required/optional and automatic defaults.</li>
<li><strong>Easily Managed Parameter Groups:</strong> Each class automatically generates its own object within a single namespace.</li>
<li><strong>Parameter Inheritance:</strong> Classes support inheritance allowing for complex configurations derived from a common base set of parameters.</li>
<li><strong>Complex Types:</strong> Nested Lists/Tuples, List/Tuples of Enum of @spock classes, List of repeated @spock classes</li>
<li><strong>Multiple Configuration File Types:</strong> Configurations are specified from YAML, TOML, or JSON files.</li>
<li><strong>Hierarchical Configuration:</strong> Compose from multiple configuration files via simple include statements.</li>
<li><strong>Command-Line Overrides:</strong> Quickly experiment by overriding a value with automatically generated command line arguments.</li>
<li><strong>Immutable:</strong> All classes are frozen preventing any misuse or accidental overwrites (to the extent they can be in Python).</li>
<li><strong>Tractability and Reproducibility:</strong> Save runtime parameter configuration to YAML, TOML, or JSON with a single chained command (with extra runtime info such as Git info, Python version, machine FQDN, etc). The saved markdown file can be used as the configuration input to reproduce prior runtime configurations.</li>
<li><strong>S3 Addon:</strong> Automatically detects s3:// URI(s) and handles loading and saving spock configuration files when an active boto3.Session is passed in (plus any additional S3Transfer configurations)</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/fidelity/spock" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Spock
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f6fbfe;--color:#53a7ee" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://www.seldon.io/tech/products/core/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/seldoncore.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://www.seldon.io/tech/products/core/" target="_blank" class="link transition-colors" data-v-61b256b6>Seldon Core</a></h3> <a href="https://github.com/SeldonIO/seldon-core" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Serving
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><!----> <tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Competes with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>KFServing</span> <!----></div><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle mr-2" data-v-61b256b6>BentoML</span> <span class="text-xs align-middle text-gray-500" data-v-61b256b6>to some extent</span></div></div></td></tr></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Seldon Core makes it easier and faster to deploy your machine learning models and experiments at scale on Kubernetes.</p>
<ul>
<li><strong>Runs anywhere</strong>: Built on Kubernetes, runs on any cloud and on premises</li>
<li><strong>Agnostic and independent</strong>: Framework agnostic, supports top ML libraries, toolkits and languages</li>
<li><strong>Runtime inference graphs</strong>: Advanced deployments with experiments, ensembles and transformers</li>
</ul>
<p>Seldon handles scaling to thousands of production machine learning models and provides advanced machine learning capabilities out of the box including Advanced Metrics, Request Logging, Explainers, Outlier Detectors, A/B Tests, Canaries and more.</p>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/Xildxp_CsmA" title="Seldon Core Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://www.seldon.io/tech/products/core/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Seldon Core
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fffef8;--color:#F6E278" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/slundberg/shap" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/shap.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/slundberg/shap" target="_blank" class="link transition-colors" data-v-61b256b6>SHAP</a></h3> <a href="https://github.com/slundberg/shap" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Explainability
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions.</p>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/slundberg/shap" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try SHAP
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/ploomber/ploomber" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/ploomber.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/ploomber/ploomber" target="_blank" class="link transition-colors" data-v-61b256b6>Ploomber</a></h3> <a href="https://github.com/ploomber/ploomber" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Works well with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Kubernetes</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>AWS Batch</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Airflow</span> <!----></div></div></td></tr> <!----></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Develop and test workflows locally, seamlessly execute them in a distributed environment.</p>
<p>Features:</p>
<ul>
<li><strong>Cloud-agnostic.</strong> Runs in Kubernetes, AWS Batch, and Airflow.</li>
<li><strong>Integrates with Jupyter.</strong> Develop interactively, deploy to the cloud without code changes.</li>
<li><strong>Incremental builds.</strong> Speed up execution by skipping tasks whose source code has not changed.</li>
<li><strong>Flexible.</strong> Supports functions, scripts, notebooks, and SQL scripts as tasks.</li>
<li><strong>Parallelization.</strong> Automatically parallelize independent tasks.</li>
<li><strong>Interactive console.</strong> Helps you debug workflows quickly.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/XCgX1AszVF4" title="Ploomber Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/ploomber/ploomber" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Ploomber
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://orchest.io" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/orchest.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://orchest.io" target="_blank" class="link transition-colors" data-v-61b256b6>Orchest</a></h3> <a href="https://github.com/orchest/orchest" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Works well with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Jupyter Notebooks</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Self-Hosted</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Cloud</span> <!----></div></div></td></tr> <!----></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Build data pipelines, the easy way!</p>
<p>No framework. No YAML. Just write Python and R code in Notebooks.</p>
<p>Features:</p>
<ul>
<li><strong>Visually construct</strong> pipelines through our user-friendly UI</li>
<li><strong>Code in Notebooks</strong></li>
<li>Run any subset of a pipeline <strong>directly or periodically</strong></li>
<li>Easily define your dependencies to run on <strong>any machine</strong></li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/BUpSVE2mtz4" title="Orchest Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://orchest.io" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Orchest
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://openpai.readthedocs.io/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/pai.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://openpai.readthedocs.io/" target="_blank" class="link transition-colors" data-v-61b256b6>OpenPAI</a></h3> <a href="https://github.com/Microsoft/pai" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>OpenPAI is an open-source platform that provides complete AI model training and resource management capabilities, it is easy to extend and supports on-premise, cloud, and hybrid environments on various scales.</p>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/C9eRaqqAOeY" title="OpenPAI Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://openpai.readthedocs.io/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try OpenPAI
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fbf8ff;--color:#AF72FD" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://mlrun.org/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/mlrun.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://mlrun.org/" target="_blank" class="link transition-colors" data-v-61b256b6>MLRun</a></h3> <a href="https://github.com/mlrun/mlrun" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Monitoring
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>MLRun is an end-to-end open-source MLOps orchestration framework to manage and automate your entire analytics and machine learning lifecycle, from data ingestion, through model development to full pipeline deployment. MLRun eases the development of machine learning pipelines at scale and helps ML teams build a robust process for moving from the research phase to fully operational production deployments.</p>
<ul>
<li><strong>Feature and Artifact Store:</strong> Handles the ingestion, processing, metadata, and storage of data and features across multiple repositories and technologies.</li>
<li><strong>Elastic Serverless Runtimes:</strong> Converts simple code to scalable and managed microservices with workload-specific runtime engines (such as Kubernetes jobs, Nuclio, Dask, Spark, and Horovod).</li>
<li><strong>ML Pipeline Automation:</strong> Automates data preparation, model training and testing, deployment of real-time production pipelines, and <strong>end-to-end model and feature monitoring</strong>.</li>
<li><strong>Central Management:</strong> Provides a unified portal for managing the entire MLOps workflow. The portal includes a UI, a CLI, and an SDK, which are accessible from anywhere.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/imiTr1aXRKU" title="MLRun Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://mlrun.org/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try MLRun
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fffef8;--color:#F6E278" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/marcotcr/lime" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/default.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/marcotcr/lime" target="_blank" class="link transition-colors" data-v-61b256b6>Lime</a></h3> <a href="https://github.com/marcotcr/lime" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Explainability
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>This project is about explaining what machine learning classifiers (or models) are doing. At the moment, we support explaining individual predictions for text classifiers or classifiers that act on tables (numpy arrays of numerical or categorical data) or. images, with a package called lime (short for local interpretable model-agnostic explanations). Lime is based on the work presented in this paper (bibtex here for citation).</p>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/hUnRCxnydCc" title="Lime Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/marcotcr/lime" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Lime
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://katonic.ai" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/katonic.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://katonic.ai" target="_blank" class="link transition-colors" data-v-61b256b6>Katonic.ai</a></h3> <!----></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Works well with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Jupyter Notebooks</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Cloud</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Python</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>R-Studio</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Tensorflow</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Spark</span> <!----></div></div></td></tr> <!----></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Katonic MLOps Platform is a collaborative platform with a Unified UI to manage all data science activities in one place and introduce MLOps practice into the production systems of customers and developers. It is a collection of cloud-native tools for all of these stages of MLOps:</p>
<ul>
<li>Data exploration</li>
<li>Feature preparation</li>
<li>Model training/tuning</li>
<li>Model serving, testing and versioning</li>
</ul>
<p>Katonic is for both data scientists and data engineers looking to build production-grade machine learning implementations and can be run either locally in your development environment or on a production cluster. Katonic provides a unified system—leveraging Kubernetes for containerization and scalability for the portability and repeatability of its pipelines.</p>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/cGl5CqSiPLw" title="Katonic.ai Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://katonic.ai" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Katonic.ai
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fffef8;--color:#F6E278" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://interpret.ml/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/interpretml.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://interpret.ml/" target="_blank" class="link transition-colors" data-v-61b256b6>InterpretML</a></h3> <a href="https://github.com/interpretml/interpret" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Explainability
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>InterpretML is an open-source package that incorporates state-of-the-art machine learning interpretability techniques under one roof. With this package, you can train interpretable glassbox models and explain blackbox systems. InterpretML helps you understand your model's global behavior, or understand the reasons behind individual predictions.</p>
<p>Interpretability is essential for:</p>
<ul>
<li>Model debugging - Why did my model make this mistake?</li>
<li>Feature Engineering - How can I improve my model?</li>
<li>Detecting fairness issues - Does my model discriminate?</li>
<li>Human-AI cooperation - How can I understand and trust the model's decisions?</li>
<li>Regulatory compliance - Does my model satisfy legal requirements?</li>
<li>High-risk applications - Healthcare, finance, judicial, ...</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/WwBeKMQ0-I8" title="InterpretML Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://interpret.ml/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try InterpretML
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f4f3f6;--color:#2b1048" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://hypervector.io" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/hypervector.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://hypervector.io" target="_blank" class="link transition-colors" data-v-61b256b6>Hypervector</a></h3> <a href="https://github.com/hypervectorio/hypervector-wrapper" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Testing
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Works well with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Github Actions</span> <!----></div></div></td></tr> <!----></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Provides API-powered <strong>synthetic data test fixtures</strong> for your tabular data-enabled features — enabling regression and integration tests to be easily built and deployed for your production ML models and data science components</p>
<ul>
<li><strong>Construct synthetic data</strong> covering important behaviours, edge cases, and under-represented areas of your input domain</li>
<li><strong>Retrieve via dedicated endpoint</strong> to your builds & continuous integration steps. No more data in version control.</li>
<li><strong>Benchmark model output</strong> to quickly detect regressions, or compare behaviours for model selection</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/877h1umtJAo" title="Hypervector Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://hypervector.io" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Hypervector
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fef5f4;--color:#F23B27" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://flyte.org/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/flyte.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://flyte.org/" target="_blank" class="link transition-colors" data-v-61b256b6>Flyte</a></h3> <a href="https://github.com/flyteorg/flyte" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Training Orchestration
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Flyte makes it easy to create concurrent, scalable, and maintainable workflows for machine learning and data processing.</p>
<ul>
<li>Kubernetes-Native Workflow Automation Platform</li>
<li>Ergonomic SDK's in Python, Java & Scala</li>
<li>Versioned & Auditable</li>
<li>Reproducible Pipelines</li>
<li>Strong Data Typing</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/1BjXC5TZAiI" title="Flyte Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://flyte.org/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Flyte
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f5fdfa;--color:#39DAA3" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://feast.dev/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/feast.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://feast.dev/" target="_blank" class="link transition-colors" data-v-61b256b6>Feast</a></h3> <a href="https://github.com/feast-dev/feast" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Feature Store
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><!----> <tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Competes with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Hopsworks</span> <!----></div></div></td></tr></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Feast is an operational data system for managing and serving machine learning features to models in production.</p>
<ul>
<li>Feast decouples your models from your data infrastructure by providing a single data access layer that abstracts feature storage from feature retrieval.</li>
<li>Feast provides both a centralized registry to which data scientists can publish features, and a battle-hardened serving layer. Together, these enable non-engineering teams to ship features into production with minimal oversight.</li>
<li>Feast solves the challenge of data leakage by providing point-in-time correct feature retrieval when exporting feature datasets for model training.</li>
<li>With Feast, data scientists can start new ML projects by selecting previously engineered features from a centralized registry, and are no longer required to develop new features for each project.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/DaNv-Wf1MBA" title="Feast Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://feast.dev/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Feast
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fffef8;--color:#F6E278" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/TeamHG-Memex/eli5" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/teamhg.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/TeamHG-Memex/eli5" target="_blank" class="link transition-colors" data-v-61b256b6>ELI5</a></h3> <a href="https://github.com/TeamHG-Memex/eli5" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Explainability
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>ELI5 is a Python library which allows to visualize and debug various Machine Learning models using unified API. It has built-in support for several ML frameworks and provides a way to explain black-box models.</p>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/s-yT5Is1G1A" title="ELI5 Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/TeamHG-Memex/eli5" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try ELI5
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fbf8ff;--color:#AF72FD" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://deepchecks.com/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/deepchecks.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://deepchecks.com/" target="_blank" class="link transition-colors" data-v-61b256b6>Deepchecks</a></h3> <!----></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Monitoring
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Validate and monitor your data and models during training, production and new version releases.</p>
<p>Features:</p>
<ul>
<li>ML Validation of training data and ML model</li>
<li>Observability of ML in production</li>
<li>Alerting about various issues in live ML systems</li>
<li>Detecting Mismatches between research and production environments</li>
<li>Quick Querying of problematic production data</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://deepchecks.com/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Deepchecks
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f7fdfe;--color:#60DFE8" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://dagshub.com/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/dagshub.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://dagshub.com/" target="_blank" class="link transition-colors" data-v-61b256b6>DAGsHub</a></h3> <!----></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Data Versioning
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>DAGsHub enables data scientists and ML engineers to work together, effectively. Integrating open-source tools like Git, DVC, MLflow, and Jenkins so that you can track and version code, data, models, pipelines, and experiments in one place.</p>
<ul>
<li><strong>Your project in one place</strong>: Manage your code, notebooks, data, models, pipelines, and experiments and easily connect to plugins for automation, all with open source tools and open formats.</li>
<li><strong>Zero configuration</strong>: Don't waste time on DevOps heavy lifting. Each DAGsHub project comes with a free, built-in DVC data storage and MLflow server, with team access controls, so you can just add the URL, and get to work.</li>
<li><strong>Diff, compare, and review anything</strong>: DAGsHub lets you diff Jupyter notebooks, tables,. images, experiments, and even MRI data, so you can compare apples to apples, review, and make sense of your work.</li>
<li><strong>Reproducibility is a click away</strong>: Get all components of an experiment on your system. It's as easy as <code>git checkout</code>.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/lrzdqEwzoo8" title="DAGsHub Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://dagshub.com/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try DAGsHub
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fefaf5;--color:#F09240" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://www.comet.ml/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/cometml.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://www.comet.ml/" target="_blank" class="link transition-colors" data-v-61b256b6>Comet</a></h3> <!----></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Experiment Tracking
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Comet enables data scientists and teams to track, compare, explain and optimize experiments and models across the model’s entire lifecycle. From training to production.</p>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/cX5tx202PXM" title="Comet Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://www.comet.ml/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Comet
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fefaf5;--color:#F09240" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="http://cml.dev/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/cml.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="http://cml.dev/" target="_blank" class="link transition-colors" data-v-61b256b6>CML</a></h3> <a href="https://github.com/iterative/cml" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Experiment Tracking
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Open-source library for implementing CI/CD in machine learning projects.</p>
<p>On every pull request, CML helps you automatically train and evaluate models, then generates a visual report with results and metrics.</p>
<ul>
<li><strong>GitFlow for data science.</strong> Use GitLab or GitHub to manage ML experiments, track who trained ML models or modified data and when. Codify data and models with DVC instead of pushing to a Git repo.</li>
<li><strong>Auto reports for ML experiments.</strong> Auto-generate reports with metrics and plots in each Git Pull Request. Rigorous engineering practices help your team make informed, data-driven decisions.</li>
<li><strong>No additional services.</strong> Build your own ML platform using just GitHub or GitLab and your favourite cloud services: AWS, Azure, GCP. No databases, services or complex setup needed.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <div class="block aspect-w-16 aspect-h-9 relative mt-10 lg:mt-6 rounded overflow-hidden group video-block" data-v-61b256b6><iframe src="https://www.youtube.com/embed/9BgIDqAzfuA" title="CML Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen loading="lazy" class="w-100 h-100 absolute left-0 top-0 object-cover" data-v-61b256b6></iframe></div> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="http://cml.dev/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try CML
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f5fdfa;--color:#39DAA3" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://github.com/quintoandar/butterfree" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/quintoandar.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://github.com/quintoandar/butterfree" target="_blank" class="link transition-colors" data-v-61b256b6>Butterfree</a></h3> <a href="https://github.com/quintoandar/butterfree" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Feature Store
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>A tool for building feature stores. Transform your raw data into beautiful features.</p>
<p>The library is centered on the following concetps:</p>
<ul>
<li>ETL: central framework to create data pipelines. Spark-based Extract, Transform and Load modules ready to use.</li>
<li>Declarative Feature Engineering: care about what you want to compute and not how to code it.</li>
<li>Feature Store Modeling: the library easily provides everything you need to process and load data to your Feature Store.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://github.com/quintoandar/butterfree" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Butterfree
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#f6fbfe;--color:#53a7ee" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://bentoml.org/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/bentoml.svg" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://bentoml.org/" target="_blank" class="link transition-colors" data-v-61b256b6>BentoML</a></h3> <a href="https://github.com/bentoml/BentoML" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Model Serving
		</div></div> <div class="mt-4 pb-6 border-b border-gray-200" data-v-61b256b6><table class="lg:block" data-v-61b256b6><tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Works well with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>AWS Lambda</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Azure Functions</span> <!----></div><div target="_blank" class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle" data-v-61b256b6>Google Cloud Run</span> <!----></div></div></td></tr> <tr class="row lg:block" data-v-61b256b6><td class="lg:block pr-7 text-sm text-gray-500 flex-shrink-0 whitespace-nowrap align-top" data-v-61b256b6><span class="block pt-1 lg:pt-0 lg:pb-2" data-v-61b256b6>Competes with:</span></td> <td class="lg:block" data-v-61b256b6><div class="-m-1 flex justify-start flex-wrap" data-v-61b256b6><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle mr-2" data-v-61b256b6>Seldon Core</span> <span class="text-xs align-middle text-gray-500" data-v-61b256b6>to some extent</span></div><div class="py-1 px-2.5 rounded border border-gray-500table-item m-1" data-v-61b256b6><span class="text-sm font-semibold align-middle mr-2" data-v-61b256b6>KFServing</span> <span class="text-xs align-middle text-gray-500" data-v-61b256b6>to some extent</span></div></div></td></tr></table></div> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>BentoML is a flexible, high-performance framework for serving, managing, and deploying machine learning models.</p>
<ul>
<li>Supports multiple ML frameworks, including Tensorflow, PyTorch, Keras, XGBoost and more</li>
<li>Cloud native deployment with Docker, Kubernetes, AWS, Azure and many more</li>
<li>High-Performance online API serving and offline batch serving</li>
<li>Web dashboards and APIs for model registry and deployment management</li>
</ul>
<p>BentoML tries to bridge the gap between Data Science and DevOps. By providing a standard interface for describing a prediction service, BentoML abstracts away how to run model inference efficiently and how model serving workloads can integrate with cloud infrastructures.</p>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://bentoml.org/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try BentoML
		</a></div></div><div class="project-card p-10 lg:p-6 rounded mb-10 lg:mb-6" style="background-color:#fefaf5;--color:#F09240" data-v-61b256b6 data-v-2b899a1e><div class="flex lg:block" data-v-61b256b6><div class="flex mr-10 lg:mr-0 flex-1 text-zero" data-v-61b256b6><div class="w-8 h-8 lg:w-6 lg:h-6 mr-5 lg:mr-4 mt-0.5 lg:mt-1 inline-block align-middle flex-shrink-0" data-v-61b256b6><a href="https://aimstack.io/" target="_blank" class="block transition-opacity hover:opacity-70" data-v-61b256b6><img src="./images/projects/aim.png" alt="project.name" loading="lazy" class="block w-full h-full transform-gpu" data-v-61b256b6></a></div> <div data-v-61b256b6><h3 class="text-2xl lg:text-xl font-bold inline mr-5 lg:mr-4 text-gray-900 align-middle" data-v-61b256b6><a href="https://aimstack.io/" target="_blank" class="link transition-colors" data-v-61b256b6>Aim</a></h3> <a href="https://github.com/aimhubio/aim" target="_blank" class="github-link inline-flex items-center text-gray-400 align-middle transition-colors my-1" data-v-61b256b6><svg xmlns="http://www.w3.org/2000/svg" class="block w-5 h-5 lg:w-4 lg:h-4 icon sprite-icons icon icon-github" data-v-0a938766 data-v-0a938766 data-v-61b256b6><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-github" data-v-0a938766 data-v-0a938766></use></svg> <!----></a></div></div> <div class="text-sm lg:text-xs text-gray-400 flex-shrink-0 whitespace-nowrap mt-1.5 lg:mt-2" data-v-61b256b6>
			Experiment Tracking
		</div></div> <!----> <div class="description text-sm text-gray-600 mt-6" data-v-61b256b6><p>Compare 1000s of AI experiments at once.</p>
<ul>
<li><strong>Open-source</strong>: Community-driven. Self-hosted and full metadata access.</li>
<li><strong>Explore & Compare</strong>: Easily search, group and aggregate metrics by any hyperparameter.</li>
<li><strong>Dashboard</strong>: Activity view and full experiments dashboard for all experiments.</li>
</ul>
</div> <img loading="lazy" data-v-61b256b6> <!----> <div class="flex items-center flex-wrap mt-10 lg:mt-8" data-v-61b256b6><a type="" href="https://aimstack.io/" target="_blank" class="rounded transition-colors px-6 lg:px-3 py-3 lg:py-2 text-sm lg:text-xs lg:font-medium text-white bg-gray-900 hover:bg-gray-800" data-v-61b256b6>
			Try Aim
		</a></div></div></div></div> <div class="transition-runner hidden" data-v-2b899a1e></div></div></div> <div class="footer text-gray-400 py-10 text-sm lg:text-xs" data-v-af4ccb18><div class="mx-auto px-10 lg:px-6 flex items-center justify-between lg:flex-col mt-5 lg:mt-10" data-v-af4ccb18><div class="flex items-center lg:flex-col" data-v-af4ccb18><svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 mr-5 lg:mr-0 flex-shrink-0 icon sprite-icons icon icon-logo" data-v-0a938766 data-v-0a938766 data-v-af4ccb18><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-logo" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-logo" data-v-0a938766 data-v-0a938766></use></svg> <div class="lg:text-center lg:mt-5" data-v-af4ccb18>
				Licensed under
				<a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" class="text-gray-600 hover:text-purple-600 transition-colors whitespace-nowrap" data-v-af4ccb18>CC BY-SA 4.0</a></div></div> <div class="flex items-center lg:mt-6 flex-shrink-0" data-v-af4ccb18><div data-v-af4ccb18>Made with</div> <div data-v-af4ccb18><svg xmlns="http://www.w3.org/2000/svg" class="heart block w-5 h-5 mx-2 text-aporiaRed icon sprite-icons icon icon-heart" data-v-0a938766 data-v-0a938766 data-v-af4ccb18><use href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-heart" xlink:href="/_nuxt/d6cc55b9c9ad776fce4732d9c5ad2dca.svg#i-heart" data-v-0a938766 data-v-0a938766></use></svg></div> <div data-v-af4ccb18>by</div> <a href="https://www.aporia.com?utm_source=mlops-toys&utm_medium=inhouse-application&utm_campaign=mlops-toys" target="_blank" class="block transition-opacity hover:opacity-70" data-v-af4ccb18><img src="/_nuxt/img/logo-aporia.68cf18d.svg" alt="Aporia" class="block ml-3 h-8 lg:h-6" data-v-af4ccb18></a></div></div></div></div></div></div><script defer src="/_nuxt/static/1666178784/explainability/state.js"></script><script src="/_nuxt/ace382d.js" defer></script><script src="/_nuxt/22f13d0.js" defer></script><script src="/_nuxt/81af258.js" defer></script><script src="/_nuxt/e3e98e8.js" defer></script><script src="/_nuxt/67a9037.js" defer></script><script src="/_nuxt/199d7de.js" defer></script><script src="/_nuxt/44ea7cd.js" defer></script>
  </body>
</html>
